{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Classes Remapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to remap the classes of the Fakeddit dataset (subreddit sources) to our binary class problem (pristine or fake).\n",
    "In particular, we will consider as \"fake\" each image coming from the \"PS battle comments\" subreddit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nello\\AppData\\Local\\Temp\\ipykernel_15772\\2574370569.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the unique list of all the possible subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique subreddit values saved to subreddit_values.json\n",
      "['mildlyinteresting', 'pareidolia', 'neutralnews', 'photoshopbattles', 'nottheonion', 'psbattle_artwork', 'fakehistoryporn', 'propagandaposters', 'upliftingnews', 'fakealbumcovers', 'subredditsimulator', 'satire', 'savedyouaclick', 'misleadingthumbnails', 'pic', 'theonion', 'confusing_perspective', 'usanews', 'usnews', 'waterfordwhispersnews', 'subsimulatorgpt2', 'fakefacts']\n"
     ]
    }
   ],
   "source": [
    "multimodal_train_tsv_path = os.getenv('MULTIMODAL_TRAIN_CLEANED_NO_EXACT_DUPLICATES_NO_IMAGEONLY_DUPLICATES_NO_CORRUPTED_TSV')\n",
    "\n",
    "df = pd.read_csv(multimodal_train_tsv_path, sep='\\t')\n",
    "\n",
    "#get unique values from the \"subreddit\" column\n",
    "unique_subreddits = list(df['subreddit'].unique())\n",
    "\n",
    "with open('subreddit_values.json', 'w') as json_file:\n",
    "    json.dump(unique_subreddits, json_file, indent=2)\n",
    "\n",
    "print(\"Unique subreddit values saved to subreddit_values.json\")\n",
    "print(unique_subreddits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add a column named \"class\" which will contain either \"fake\" or \"pristine\" depending on the \"subreddit\" column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Counts:\n",
      "class\n",
      "pristine    385871\n",
      "fake        157126\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Counts:\n",
      "class\n",
      "pristine    41567\n",
      "fake        16480\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation Counts:\n",
      "class\n",
      "pristine    40909\n",
      "fake        16580\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=> Total \"pristine\": 468347 | Total \"fake\": 190186\n"
     ]
    }
   ],
   "source": [
    "multimodal_train_tsv_path = os.getenv('MULTIMODAL_TRAIN_CLEANED_NO_EXACT_DUPLICATES_NO_IMAGEONLY_DUPLICATES_NO_CORRUPTED_TSV')\n",
    "multimodal_test_tsv_path = os.getenv('MULTIMODAL_TEST_CLEANED_NO_EXACT_DUPLICATES_NO_CORRUPTED_TSV')\n",
    "multimodal_validation_tsv_path = os.getenv('MULTIMODAL_VAL_CLEANED_NO_EXACT_DUPLICATES_NO_CORRUPTED_TSV')\n",
    "\n",
    "df_train = pd.read_csv(multimodal_train_tsv_path, sep='\\t')\n",
    "df_test = pd.read_csv(multimodal_test_tsv_path, sep='\\t')\n",
    "df_val = pd.read_csv(multimodal_validation_tsv_path, sep='\\t')\n",
    "\n",
    "#create a new column \"class\" and set default value to \"pristine\"\n",
    "df_train['class'] = 'pristine'\n",
    "df_test['class'] = 'pristine'\n",
    "df_val['class'] = 'pristine'\n",
    "\n",
    "#then set the value to \"fake\" for rows where \"subreddit\" is equal to \"psbattle_artwork\"\n",
    "df_train.loc[df_train['subreddit'] == 'psbattle_artwork', 'class'] = 'fake'\n",
    "df_test.loc[df_test['subreddit'] == 'psbattle_artwork', 'class'] = 'fake'\n",
    "df_val.loc[df_val['subreddit'] == 'psbattle_artwork', 'class'] = 'fake'\n",
    "\n",
    "df_train.to_csv(\"train_tsv_with_class.tsv\", sep='\\t', index=False)\n",
    "df_test.to_csv(\"test_tsv_with_class.tsv\", sep='\\t', index=False)\n",
    "df_val.to_csv(\"val_tsv_with_class.tsv\", sep='\\t', index=False)\n",
    "\n",
    "train_counts = df_train['class'].value_counts()\n",
    "test_counts = df_test['class'].value_counts()\n",
    "val_counts = df_val['class'].value_counts()\n",
    "\n",
    "print(\"Train Counts:\")\n",
    "print(train_counts)\n",
    "print(\"\\nTest Counts:\")\n",
    "print(test_counts)\n",
    "print(\"\\nValidation Counts:\")\n",
    "print(val_counts)\n",
    "\n",
    "print(\"\\n=> Total \\\"pristine\\\": \"+ str(train_counts['pristine']+test_counts['pristine']+val_counts['pristine'])+\" | Total \\\"fake\\\": \"+str(train_counts['fake']+test_counts['fake']+val_counts['fake']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
