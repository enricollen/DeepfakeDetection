{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nello\\AppData\\Local\\Temp\\ipykernel_7496\\1398488637.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\nello\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nello\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Continue from cleaning phase, showing the cardinalities of the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Counts:\n",
      "class\n",
      "pristine    385871\n",
      "fake        157126\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Counts:\n",
      "class\n",
      "pristine    41567\n",
      "fake        16480\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation Counts:\n",
      "class\n",
      "pristine    40909\n",
      "fake        16580\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=> Total \"pristine\": 468347 | Total \"fake\": 190186\n"
     ]
    }
   ],
   "source": [
    "multimodal_train_tsv_path = os.getenv('MULTIMODAL_TRAIN_CLEANED_WITH_CLASS_TSV')\n",
    "multimodal_test_tsv_path = os.getenv('MULTIMODAL_TEST_CLEANED_WITH_CLASS_TSV')\n",
    "multimodal_validation_tsv_path = os.getenv('MULTIMODAL_VAL_CLEANED_WITH_CLASS_TSV')\n",
    "\n",
    "df_train = pd.read_csv(multimodal_train_tsv_path, sep='\\t')\n",
    "df_test = pd.read_csv(multimodal_test_tsv_path, sep='\\t')\n",
    "df_val = pd.read_csv(multimodal_validation_tsv_path, sep='\\t')\n",
    "\n",
    "train_counts = df_train['class'].value_counts()\n",
    "test_counts = df_test['class'].value_counts()\n",
    "val_counts = df_val['class'].value_counts()\n",
    "\n",
    "print(\"Train Counts:\")\n",
    "print(train_counts)\n",
    "print(\"\\nTest Counts:\")\n",
    "print(test_counts)\n",
    "print(\"\\nValidation Counts:\")\n",
    "print(val_counts)\n",
    "\n",
    "print(\"\\n=> Total \\\"pristine\\\": \"+ str(train_counts['pristine']+test_counts['pristine']+val_counts['pristine'])+\" | Total \\\"fake\\\": \"+str(train_counts['fake']+test_counts['fake']+val_counts['fake']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Select 250.000 pristine images to be captioned from train, test and val sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will select the first 20.000 from test, 20.000 from val, and 210.000 from train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected train pristine shape:  (210000, 17)\n",
      "Selected test pristine shape:  (20000, 17)\n",
      "Selected val pristine shape:  (20000, 17)\n"
     ]
    }
   ],
   "source": [
    "# Select the first 210,000 pristine images from the train set\n",
    "selected_train_pristine = df_train[df_train['class'] == 'pristine'].head(210000)\n",
    "\n",
    "# Select the first 20,000 pristine images from the test set\n",
    "selected_test_pristine = df_test[df_test['class'] == 'pristine'].head(20000)\n",
    "\n",
    "# Select the first 20,000 pristine images from the validation set\n",
    "selected_val_pristine = df_val[df_val['class'] == 'pristine'].head(20000)\n",
    "\n",
    "print(\"Selected train pristine shape: \", selected_train_pristine.shape)\n",
    "print(\"Selected test pristine shape: \", selected_test_pristine.shape)\n",
    "print(\"Selected val pristine shape: \", selected_val_pristine.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the selected pristine of each set to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_train_pristine.to_csv(\"csv/selected_train_pristine.csv\", index=False)\n",
    "selected_test_pristine.to_csv(\"csv/selected_test_pristine.csv\", index=False)\n",
    "selected_val_pristine.to_csv(\"csv/selected_val_pristine.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Define the ImageCaptioner class to be used to caption the pristine images from the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCaptioner:\n",
    "    def __init__(self, device=0, model=\"Salesforce/blip-image-captioning-base\"):\n",
    "        self.device = device\n",
    "        self.captioner = pipeline(\n",
    "            \"image-to-text\",\n",
    "            model=model,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def process_images(self, image_paths, batch_size=500, error_file=\"error_images.txt\"):\n",
    "        total_inference_time = 0\n",
    "        result_dict = {\"image_name\": [], \"caption\": []}\n",
    "\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            batch_paths = image_paths[i:i + batch_size]\n",
    "\n",
    "            with tqdm(total=len(batch_paths),\n",
    "                    desc=f\"Processing Batch {i // batch_size + 1}/{len(image_paths) // batch_size}\", unit=\"image\") as pbar:\n",
    "                start_time = time.time()\n",
    "\n",
    "                try:\n",
    "                    captions = self.captioner(batch_paths, max_new_tokens=100)\n",
    "                except Exception as ex:\n",
    "                    if not os.path.exists(error_file):\n",
    "                        with open(error_file, \"w\"):\n",
    "                            pass \n",
    "\n",
    "                    with open(error_file, \"a\") as error_file_writer:\n",
    "                        error_file_writer.write(\"\\n\".join(batch_paths) + \"\\n\")\n",
    "                    pbar.update(len(batch_paths))\n",
    "                    continue  # Skip to the next iteration if an exception occurs\n",
    "\n",
    "                end_time = time.time()\n",
    "                batch_inference_time = end_time - start_time\n",
    "                total_inference_time += batch_inference_time\n",
    "\n",
    "                for path, caption in zip(batch_paths, captions):\n",
    "                    image_name = os.path.splitext(os.path.basename(path))[0]  # remove .jpg\n",
    "                    result_dict[\"image_name\"].append(image_name)\n",
    "                    result_dict[\"caption\"].append(caption[0][\"generated_text\"])\n",
    "                    pbar.update(1)\n",
    "\n",
    "        avg_time_per_image = total_inference_time / len(image_paths)\n",
    "        print(f\"\\nTotal Inference Time: {total_inference_time:.2f} seconds\")\n",
    "        print(f\"Avg Time Per Image Caption: {avg_time_per_image:.4f} seconds\")\n",
    "\n",
    "        result_df = pd.DataFrame(result_dict)\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "captioner = ImageCaptioner(model=\"Salesforce/blip-image-captioning-large\")\n",
    "DATASET_DIR = os.getenv('DATASET_DIR')\n",
    "BATCH_SIZE = int(os.getenv('BATCH_SIZE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the method to be called onto one set at a time, to caption all the images of a set (e.g. training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_and_save_images(df, save_path):\n",
    "    # Extract paths of selected pristine images\n",
    "    pristine_paths = [os.path.join(DATASET_DIR, f\"{image_name}.jpg\") for image_name in df['id']]\n",
    "\n",
    "    # Process and caption images\n",
    "    generated_captions_df = captioner.process_images(image_paths=pristine_paths, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Merge the original captions from df with the generated captions\n",
    "    result_df = pd.merge(df, generated_captions_df, left_on=\"id\", right_on=\"image_name\", how=\"left\")\n",
    "\n",
    "    # Create a new DataFrame with 'id', 'original_caption', and 'caption'\n",
    "    result_df = result_df[['id', 'clean_title', 'caption']]\n",
    "\n",
    "    result_df = result_df.rename(columns={'clean_title': 'original_caption', 'caption': 'generated_caption'})\n",
    "    result_df.to_csv(save_path, index=False, header=True, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Perform Captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the csv of the selected pristine for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_TRAIN_PRISTINE_CSV_PATH = os.getenv('SELECTED_TRAIN_PRISTINE_CSV_PATH')\n",
    "SELECTED_TEST_PRISTINE_CSV_PATH = os.getenv('SELECTED_TEST_PRISTINE_CSV_PATH')\n",
    "SELECTED_VAL_PRISTINE_CSV_PATH = os.getenv('SELECTED_VAL_PRISTINE_CSV_PATH')\n",
    "\n",
    "selected_train_pristine = pd.read_csv(SELECTED_TRAIN_PRISTINE_CSV_PATH, sep=',')\n",
    "selected_test_pristine = pd.read_csv(SELECTED_TEST_PRISTINE_CSV_PATH, sep=',')\n",
    "selected_val_pristine = pd.read_csv(SELECTED_VAL_PRISTINE_CSV_PATH, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PRISTINE_CAPTIONED = os.getenv('TRAINING_PRISTINE_CAPTIONED')\n",
    "TEST_PRISTINE_CAPTIONED = os.getenv('TEST_PRISTINE_CAPTIONED')\n",
    "VAL_PRISTINE_CAPTIONED = os.getenv('VAL_PRISTINE_CAPTIONED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caption 210.000 images from training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_and_save_images(selected_train_pristine, TRAINING_PRISTINE_CAPTIONED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caption 20.000 images from test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch 1/40: 100%|██████████| 500/500 [01:32<00:00,  5.38image/s] \n",
      "Processing Batch 2/40: 100%|██████████| 500/500 [01:32<00:00,  5.39image/s] \n",
      "Processing Batch 3/40:   0%|          | 0/500 [00:00<?, ?image/s]c:\\Users\\nello\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Processing Batch 3/40: 100%|██████████| 500/500 [01:33<00:00,  5.37image/s] \n",
      "Processing Batch 4/40: 100%|██████████| 500/500 [01:34<00:00,  5.30image/s] \n",
      "Processing Batch 5/40: 100%|██████████| 500/500 [01:33<00:00,  5.35image/s] \n",
      "Processing Batch 6/40: 100%|██████████| 500/500 [01:34<00:00,  5.27image/s] \n",
      "Processing Batch 7/40: 100%|██████████| 500/500 [01:35<00:00,  5.22image/s] \n",
      "Processing Batch 8/40: 100%|██████████| 500/500 [01:35<00:00,  5.25image/s] \n",
      "Processing Batch 9/40: 100%|██████████| 500/500 [01:35<00:00,  5.25image/s] \n",
      "Processing Batch 10/40: 100%|██████████| 500/500 [01:40<00:00,  4.97image/s]  \n",
      "Processing Batch 11/40:   0%|          | 0/500 [00:00<?, ?image/s]c:\\Users\\nello\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Processing Batch 11/40: 100%|██████████| 500/500 [01:35<00:00,  5.23image/s] \n",
      "Processing Batch 12/40: 100%|██████████| 500/500 [01:35<00:00,  5.22image/s] \n",
      "Processing Batch 13/40: 100%|██████████| 500/500 [01:35<00:00,  5.26image/s] \n",
      "Processing Batch 14/40: 100%|██████████| 500/500 [01:34<00:00,  5.31image/s] \n",
      "Processing Batch 15/40: 100%|██████████| 500/500 [01:35<00:00,  5.23image/s] \n",
      "Processing Batch 16/40: 100%|██████████| 500/500 [01:28<00:00,  5.65image/s] \n",
      "Processing Batch 17/40: 100%|██████████| 500/500 [01:26<00:00,  5.79image/s] \n",
      "Processing Batch 18/40: 100%|██████████| 500/500 [01:21<00:00,  6.13image/s] \n",
      "Processing Batch 19/40: 100%|██████████| 500/500 [01:23<00:00,  5.99image/s] \n",
      "Processing Batch 20/40: 100%|██████████| 500/500 [01:19<00:00,  6.27image/s] \n",
      "Processing Batch 21/40: 100%|██████████| 500/500 [01:29<00:00,  5.59image/s] \n",
      "Processing Batch 22/40: 100%|██████████| 500/500 [01:28<00:00,  5.65image/s] \n",
      "Processing Batch 23/40: 100%|██████████| 500/500 [01:50<00:00,  4.51image/s]  \n",
      "Processing Batch 24/40: 100%|██████████| 500/500 [02:28<00:00,  3.37image/s]  \n",
      "Processing Batch 25/40: 100%|██████████| 500/500 [01:54<00:00,  4.38image/s]  \n",
      "Processing Batch 26/40: 100%|██████████| 500/500 [01:22<00:00,  6.09image/s] \n",
      "Processing Batch 27/40: 100%|██████████| 500/500 [01:21<00:00,  6.15image/s] \n",
      "Processing Batch 28/40: 100%|██████████| 500/500 [01:27<00:00,  5.74image/s] \n",
      "Processing Batch 29/40: 100%|██████████| 500/500 [01:25<00:00,  5.87image/s] \n",
      "Processing Batch 30/40: 100%|██████████| 500/500 [01:24<00:00,  5.95image/s] \n",
      "Processing Batch 31/40: 100%|██████████| 500/500 [01:22<00:00,  6.06image/s] \n",
      "Processing Batch 32/40: 100%|██████████| 500/500 [01:23<00:00,  5.99image/s] \n",
      "Processing Batch 33/40: 100%|██████████| 500/500 [01:22<00:00,  6.05image/s] \n",
      "Processing Batch 34/40: 100%|██████████| 500/500 [01:20<00:00,  6.20image/s] \n",
      "Processing Batch 35/40: 100%|██████████| 500/500 [01:21<00:00,  6.14image/s] \n",
      "Processing Batch 36/40: 100%|██████████| 500/500 [01:22<00:00,  6.04image/s] \n",
      "Processing Batch 37/40: 100%|██████████| 500/500 [01:25<00:00,  5.82image/s] \n",
      "Processing Batch 38/40: 100%|██████████| 500/500 [01:20<00:00,  6.23image/s] \n",
      "Processing Batch 39/40: 100%|██████████| 500/500 [01:21<00:00,  6.14image/s] \n",
      "Processing Batch 40/40: 100%|██████████| 500/500 [01:19<00:00,  6.26image/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Inference Time: 3635.98 seconds\n",
      "Avg Time Per Image Caption: 0.1818 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "caption_and_save_images(selected_test_pristine, TEST_PRISTINE_CAPTIONED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caption 20.000 images from validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch 1/40: 100%|██████████| 500/500 [01:29<00:00,  5.58image/s] \n",
      "Processing Batch 2/40: 100%|██████████| 500/500 [01:24<00:00,  5.92image/s] \n",
      "Processing Batch 3/40: 100%|██████████| 500/500 [01:28<00:00,  5.64image/s] \n",
      "Processing Batch 4/40: 100%|██████████| 500/500 [01:29<00:00,  5.58image/s] \n",
      "Processing Batch 5/40: 100%|██████████| 500/500 [01:27<00:00,  5.70image/s] \n",
      "Processing Batch 6/40: 100%|██████████| 500/500 [01:25<00:00,  5.86image/s] \n",
      "Processing Batch 7/40: 100%|██████████| 500/500 [01:27<00:00,  5.72image/s] \n",
      "Processing Batch 8/40: 100%|██████████| 500/500 [01:27<00:00,  5.70image/s] \n",
      "Processing Batch 9/40: 100%|██████████| 500/500 [01:26<00:00,  5.79image/s] \n",
      "Processing Batch 10/40: 100%|██████████| 500/500 [01:25<00:00,  5.82image/s] \n",
      "Processing Batch 11/40:   0%|          | 0/500 [00:00<?, ?image/s]c:\\Users\\nello\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Processing Batch 11/40: 100%|██████████| 500/500 [01:29<00:00,  5.59image/s] \n",
      "Processing Batch 12/40:   0%|          | 0/500 [00:00<?, ?image/s]c:\\Users\\nello\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Processing Batch 12/40: 100%|██████████| 500/500 [01:28<00:00,  5.64image/s] \n",
      "Processing Batch 13/40: 100%|██████████| 500/500 [01:27<00:00,  5.73image/s] \n",
      "Processing Batch 14/40: 100%|██████████| 500/500 [01:27<00:00,  5.70image/s] \n",
      "Processing Batch 15/40: 100%|██████████| 500/500 [01:29<00:00,  5.59image/s] \n",
      "Processing Batch 16/40: 100%|██████████| 500/500 [01:27<00:00,  5.69image/s] \n",
      "Processing Batch 17/40: 100%|██████████| 500/500 [01:27<00:00,  5.70image/s] \n",
      "Processing Batch 18/40: 100%|██████████| 500/500 [01:27<00:00,  5.73image/s] \n",
      "Processing Batch 19/40: 100%|██████████| 500/500 [01:28<00:00,  5.66image/s] \n",
      "Processing Batch 20/40: 100%|██████████| 500/500 [01:27<00:00,  5.73image/s] \n",
      "Processing Batch 21/40: 100%|██████████| 500/500 [01:28<00:00,  5.62image/s] \n",
      "Processing Batch 22/40: 100%|██████████| 500/500 [01:27<00:00,  5.73image/s] \n",
      "Processing Batch 23/40: 100%|██████████| 500/500 [01:29<00:00,  5.61image/s] \n",
      "Processing Batch 24/40: 100%|██████████| 500/500 [01:26<00:00,  5.76image/s] \n",
      "Processing Batch 25/40: 100%|██████████| 500/500 [01:27<00:00,  5.72image/s] \n",
      "Processing Batch 26/40: 100%|██████████| 500/500 [01:27<00:00,  5.74image/s] \n",
      "Processing Batch 27/40: 100%|██████████| 500/500 [01:27<00:00,  5.73image/s] \n",
      "Processing Batch 28/40: 100%|██████████| 500/500 [01:24<00:00,  5.90image/s] \n",
      "Processing Batch 29/40: 100%|██████████| 500/500 [01:26<00:00,  5.80image/s] \n",
      "Processing Batch 30/40: 100%|██████████| 500/500 [01:53<00:00,  4.40image/s]  \n",
      "Processing Batch 31/40: 100%|██████████| 500/500 [01:27<00:00,  5.71image/s] \n",
      "Processing Batch 32/40: 100%|██████████| 500/500 [01:25<00:00,  5.84image/s] \n",
      "Processing Batch 33/40: 100%|██████████| 500/500 [01:26<00:00,  5.76image/s] \n",
      "Processing Batch 34/40: 100%|██████████| 500/500 [01:26<00:00,  5.81image/s] \n",
      "Processing Batch 35/40: 100%|██████████| 500/500 [01:29<00:00,  5.59image/s] \n",
      "Processing Batch 36/40: 100%|██████████| 500/500 [01:26<00:00,  5.81image/s] \n",
      "Processing Batch 37/40: 100%|██████████| 500/500 [01:27<00:00,  5.69image/s] \n",
      "Processing Batch 38/40: 100%|██████████| 500/500 [01:27<00:00,  5.70image/s] \n",
      "Processing Batch 39/40: 100%|██████████| 500/500 [01:32<00:00,  5.41image/s] \n",
      "Processing Batch 40/40: 100%|██████████| 500/500 [01:27<00:00,  5.70image/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Inference Time: 3529.75 seconds\n",
      "Avg Time Per Image Caption: 0.1765 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "caption_and_save_images(selected_val_pristine, VAL_PRISTINE_CAPTIONED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Fix buggy captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the buggy generated captions by eliminating the words containing the suffix \"araf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAINING_PRISTINE_CAPTIONED)\n",
    "\n",
    "# Remove words containing \"araf\" from the 'generated_caption' column\n",
    "df['generated_caption'] = df['generated_caption'].apply(lambda x: ' '.join([word for word in str(x).split() if 'araf' not in word]))\n",
    "\n",
    "df.head()\n",
    "df.to_csv(TRAINING_PRISTINE_CAPTIONED, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TEST_PRISTINE_CAPTIONED)\n",
    "\n",
    "# Remove words containing \"araf\" from the 'generated_caption' column\n",
    "df['generated_caption'] = df['generated_caption'].apply(lambda x: ' '.join([word for word in str(x).split() if 'araf' not in word]))\n",
    "\n",
    "df.head()\n",
    "df.to_csv(TEST_PRISTINE_CAPTIONED, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(VAL_PRISTINE_CAPTIONED)\n",
    "\n",
    "# Remove words containing \"araf\" from the 'generated_caption' column\n",
    "df['generated_caption'] = df['generated_caption'].apply(lambda x: ' '.join([word for word in str(x).split() if 'araf' not in word]))\n",
    "\n",
    "df.head()\n",
    "df.to_csv(VAL_PRISTINE_CAPTIONED, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Create the final csv for the captioning phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 3 final csv where i merge the generated captions and some of the column of the selected_pristine csv.\n",
    "\n",
    "The resulting csv will have the following structure:\n",
    "\n",
    "id | author | original_caption | generated_caption | num_comments | class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_TRAIN_PRISTINE_CSV_PATH = os.getenv('SELECTED_TRAIN_PRISTINE_CSV_PATH')\n",
    "SELECTED_TEST_PRISTINE_CSV_PATH = os.getenv('SELECTED_TEST_PRISTINE_CSV_PATH')\n",
    "SELECTED_VAL_PRISTINE_CSV_PATH = os.getenv('SELECTED_VAL_PRISTINE_CSV_PATH')\n",
    "\n",
    "selected_train_pristine = pd.read_csv(SELECTED_TRAIN_PRISTINE_CSV_PATH, sep=',')\n",
    "selected_test_pristine = pd.read_csv(SELECTED_TEST_PRISTINE_CSV_PATH, sep=',')\n",
    "selected_val_pristine = pd.read_csv(SELECTED_VAL_PRISTINE_CSV_PATH, sep=',')\n",
    "\n",
    "TRAINING_PRISTINE_CAPTIONED = os.getenv('TRAINING_PRISTINE_CAPTIONED')\n",
    "TEST_PRISTINE_CAPTIONED = os.getenv('TEST_PRISTINE_CAPTIONED')\n",
    "VAL_PRISTINE_CAPTIONED = os.getenv('VAL_PRISTINE_CAPTIONED')\n",
    "\n",
    "train_pristine_captioned = pd.read_csv(TRAINING_PRISTINE_CAPTIONED, sep=',')\n",
    "test_pristine_captioned = pd.read_csv(TEST_PRISTINE_CAPTIONED, sep=',')\n",
    "val_pristine_captioned = pd.read_csv(VAL_PRISTINE_CAPTIONED, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>hasImage</th>\n",
       "      <th>id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>linked_submission_id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>3_way_label</th>\n",
       "      <th>6_way_label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexithymia</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>1.551641e+09</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>True</td>\n",
       "      <td>awxhir</td>\n",
       "      <td>https://external-preview.redd.it/WylDbZrnbvZdB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>My Walgreens offbrand Mucinex was engraved wit...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VIDCAs17</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>1.534727e+09</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>True</td>\n",
       "      <td>98pbid</td>\n",
       "      <td>https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>119</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>This concerned sink with a tiny hat</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prometheus1123</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>1.496511e+09</td>\n",
       "      <td>aljazeera.com</td>\n",
       "      <td>True</td>\n",
       "      <td>6f2cy5</td>\n",
       "      <td>https://external-preview.redd.it/6fNhdbc6K1vFA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>neutralnews</td>\n",
       "      <td>Hackers leak emails from UAE ambassador to US</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>1.471341e+09</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>True</td>\n",
       "      <td>4xypkv</td>\n",
       "      <td>https://external-preview.redd.it/HLtVNhTR6wtYt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>250</td>\n",
       "      <td>photoshopbattles</td>\n",
       "      <td>PsBattle: Puppy taking in the view</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rikR3ith</td>\n",
       "      <td>i found a face in my sheet music too</td>\n",
       "      <td>1.525318e+09</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>True</td>\n",
       "      <td>8gnet9</td>\n",
       "      <td>https://preview.redd.it/ri7ut2wn8kv01.jpg?widt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>I found a face in my sheet music too!</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                        clean_title  \\\n",
       "0     Alexithymia  my walgreens offbrand mucinex was engraved wit...   \n",
       "1        VIDCAs17                this concerned sink with a tiny hat   \n",
       "2  prometheus1123      hackers leak emails from uae ambassador to us   \n",
       "3             NaN                           puppy taking in the view   \n",
       "4       3rikR3ith               i found a face in my sheet music too   \n",
       "\n",
       "    created_utc         domain  hasImage      id  \\\n",
       "0  1.551641e+09    i.imgur.com      True  awxhir   \n",
       "1  1.534727e+09      i.redd.it      True  98pbid   \n",
       "2  1.496511e+09  aljazeera.com      True  6f2cy5   \n",
       "3  1.471341e+09    i.imgur.com      True  4xypkv   \n",
       "4  1.525318e+09      i.redd.it      True  8gnet9   \n",
       "\n",
       "                                           image_url  linked_submission_id  \\\n",
       "0  https://external-preview.redd.it/WylDbZrnbvZdB...                   NaN   \n",
       "1  https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...                   NaN   \n",
       "2  https://external-preview.redd.it/6fNhdbc6K1vFA...                   NaN   \n",
       "3  https://external-preview.redd.it/HLtVNhTR6wtYt...                   NaN   \n",
       "4  https://preview.redd.it/ri7ut2wn8kv01.jpg?widt...                   NaN   \n",
       "\n",
       "   num_comments  score          subreddit  \\\n",
       "0           2.0     12  mildlyinteresting   \n",
       "1           2.0    119         pareidolia   \n",
       "2           1.0     44        neutralnews   \n",
       "3          26.0    250   photoshopbattles   \n",
       "4           2.0     13         pareidolia   \n",
       "\n",
       "                                               title  upvote_ratio  \\\n",
       "0  My Walgreens offbrand Mucinex was engraved wit...          0.84   \n",
       "1                This concerned sink with a tiny hat          0.99   \n",
       "2      Hackers leak emails from UAE ambassador to US          0.92   \n",
       "3                 PsBattle: Puppy taking in the view          0.95   \n",
       "4              I found a face in my sheet music too!          0.84   \n",
       "\n",
       "   2_way_label  3_way_label  6_way_label     class  \n",
       "0            1            0            0  pristine  \n",
       "1            0            2            2  pristine  \n",
       "2            1            0            0  pristine  \n",
       "3            1            0            0  pristine  \n",
       "4            0            2            2  pristine  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_train_pristine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>generated_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awxhir</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>a close up of a person holding a pill in their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98pbid</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>there is a white sink with a soap dispenser on it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6f2cy5</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>man in a suit sitting in a chair in a room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4xypkv</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>there is a dog that is sitting in the grass lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8gnet9</td>\n",
       "      <td>i found a face in my sheet music too</td>\n",
       "      <td>a close up of a sheet of music with notes and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                   original_caption  \\\n",
       "0  awxhir  my walgreens offbrand mucinex was engraved wit...   \n",
       "1  98pbid                this concerned sink with a tiny hat   \n",
       "2  6f2cy5      hackers leak emails from uae ambassador to us   \n",
       "3  4xypkv                           puppy taking in the view   \n",
       "4  8gnet9               i found a face in my sheet music too   \n",
       "\n",
       "                                   generated_caption  \n",
       "0  a close up of a person holding a pill in their...  \n",
       "1  there is a white sink with a soap dispenser on it  \n",
       "2         man in a suit sitting in a chair in a room  \n",
       "3  there is a dog that is sitting in the grass lo...  \n",
       "4  a close up of a sheet of music with notes and ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pristine_captioned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now i merge the csv in order to produce 3 final ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CAPTIONED_FINAL = os.getenv('TRAIN_CAPTIONED_FINAL')\n",
    "TEST_CAPTIONED_FINAL = os.getenv('TEST_CAPTIONED_FINAL')\n",
    "VAL_CAPTIONED_FINAL = os.getenv('VAL_CAPTIONED_FINAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>generated_caption</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awxhir</td>\n",
       "      <td>Alexithymia</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>a close up of a person holding a pill in their...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98pbid</td>\n",
       "      <td>VIDCAs17</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>there is a white sink with a soap dispenser on it</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6f2cy5</td>\n",
       "      <td>prometheus1123</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>man in a suit sitting in a chair in a room</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4xypkv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>there is a dog that is sitting in the grass lo...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8gnet9</td>\n",
       "      <td>3rikR3ith</td>\n",
       "      <td>i found a face in my sheet music too</td>\n",
       "      <td>a close up of a sheet of music with notes and ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id          author                                   original_caption  \\\n",
       "0  awxhir     Alexithymia  my walgreens offbrand mucinex was engraved wit...   \n",
       "1  98pbid        VIDCAs17                this concerned sink with a tiny hat   \n",
       "2  6f2cy5  prometheus1123      hackers leak emails from uae ambassador to us   \n",
       "3  4xypkv             NaN                           puppy taking in the view   \n",
       "4  8gnet9       3rikR3ith               i found a face in my sheet music too   \n",
       "\n",
       "                                   generated_caption  num_comments     class  \n",
       "0  a close up of a person holding a pill in their...           2.0  pristine  \n",
       "1  there is a white sink with a soap dispenser on it           2.0  pristine  \n",
       "2         man in a suit sitting in a chair in a room           1.0  pristine  \n",
       "3  there is a dog that is sitting in the grass lo...          26.0  pristine  \n",
       "4  a close up of a sheet of music with notes and ...           2.0  pristine  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge join on 'id' column\n",
    "merged_df = pd.merge(selected_train_pristine[['id', 'author', 'num_comments', 'class']], \n",
    "                     train_pristine_captioned[['id', 'original_caption', 'generated_caption']], \n",
    "                     on='id', how='inner')\n",
    "\n",
    "# Reorder columns\n",
    "result_df = merged_df[['id', 'author', 'original_caption', 'generated_caption', 'num_comments', 'class']]\n",
    "\n",
    "result_df.to_csv(TRAIN_CAPTIONED_FINAL, index=False)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>generated_caption</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0gl7r</td>\n",
       "      <td>chaseoes</td>\n",
       "      <td>pd phoenix car thief gets instructions from yo...</td>\n",
       "      <td>a man is shown in a police photo and a yellow ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0xdqy</td>\n",
       "      <td>SFepicure</td>\n",
       "      <td>as trump accuses iran he has one problem his o...</td>\n",
       "      <td>a close up of a person in a suit and tie speak...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7o9rmx</td>\n",
       "      <td>fragments_from_Work</td>\n",
       "      <td>believers hezbollah</td>\n",
       "      <td>a close up of a soldier in a field with a rifle</td>\n",
       "      <td>40.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bdfxf1</td>\n",
       "      <td>SovietTurnipFarmer</td>\n",
       "      <td>the rise of italian fascism circa</td>\n",
       "      <td>a screenshot of a cell phone showing a picture...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8g3xtm</td>\n",
       "      <td>HR_Paperstacks_402</td>\n",
       "      <td>trumps pick to lead ice who touted surge in im...</td>\n",
       "      <td>the washington post logo with a statue of abra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id               author  \\\n",
       "0  c0gl7r             chaseoes   \n",
       "1  c0xdqy            SFepicure   \n",
       "2  7o9rmx  fragments_from_Work   \n",
       "3  bdfxf1   SovietTurnipFarmer   \n",
       "4  8g3xtm   HR_Paperstacks_402   \n",
       "\n",
       "                                    original_caption  \\\n",
       "0  pd phoenix car thief gets instructions from yo...   \n",
       "1  as trump accuses iran he has one problem his o...   \n",
       "2                                believers hezbollah   \n",
       "3                  the rise of italian fascism circa   \n",
       "4  trumps pick to lead ice who touted surge in im...   \n",
       "\n",
       "                                   generated_caption  num_comments     class  \n",
       "0  a man is shown in a police photo and a yellow ...           2.0  pristine  \n",
       "1  a close up of a person in a suit and tie speak...           4.0  pristine  \n",
       "2    a close up of a soldier in a field with a rifle          40.0  pristine  \n",
       "3  a screenshot of a cell phone showing a picture...           2.0  pristine  \n",
       "4  the washington post logo with a statue of abra...           1.0  pristine  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(selected_test_pristine[['id', 'author', 'num_comments', 'class']], \n",
    "                     test_pristine_captioned[['id', 'original_caption', 'generated_caption']], \n",
    "                     on='id', how='inner')\n",
    "\n",
    "result_df = merged_df[['id', 'author', 'original_caption', 'generated_caption', 'num_comments', 'class']]\n",
    "\n",
    "result_df.to_csv(TEST_CAPTIONED_FINAL, index=False)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>generated_caption</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cypw96</td>\n",
       "      <td>singingdart7854</td>\n",
       "      <td>my xbox controller says hi</td>\n",
       "      <td>someone is holding a remote control for a vide...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d0bzlq</td>\n",
       "      <td>mandal0re</td>\n",
       "      <td>new image from the mandalorian</td>\n",
       "      <td>there are three people standing on a porch of ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bq3yuk</td>\n",
       "      <td>Thebubster2001</td>\n",
       "      <td>this tree i found with a solo cup on it</td>\n",
       "      <td>there is a red frisbee that is stuck in the trees</td>\n",
       "      <td>8.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8rsoq0</td>\n",
       "      <td>jokkstermokkster</td>\n",
       "      <td>dude id feel the same if i got a pole through ...</td>\n",
       "      <td>there is a close up of a window with a small f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33sekv</td>\n",
       "      <td>alleged_redditor</td>\n",
       "      <td>japanese black pine tree</td>\n",
       "      <td>bonsai tree in a pot on a stone pedestal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pristine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id            author  \\\n",
       "0  cypw96   singingdart7854   \n",
       "1  d0bzlq         mandal0re   \n",
       "2  bq3yuk    Thebubster2001   \n",
       "3  8rsoq0  jokkstermokkster   \n",
       "4  33sekv  alleged_redditor   \n",
       "\n",
       "                                    original_caption  \\\n",
       "0                         my xbox controller says hi   \n",
       "1                     new image from the mandalorian   \n",
       "2            this tree i found with a solo cup on it   \n",
       "3  dude id feel the same if i got a pole through ...   \n",
       "4                           japanese black pine tree   \n",
       "\n",
       "                                   generated_caption  num_comments     class  \n",
       "0  someone is holding a remote control for a vide...           4.0  pristine  \n",
       "1  there are three people standing on a porch of ...           5.0  pristine  \n",
       "2  there is a red frisbee that is stuck in the trees           8.0  pristine  \n",
       "3  there is a close up of a window with a small f...           0.0  pristine  \n",
       "4           bonsai tree in a pot on a stone pedestal           2.0  pristine  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(selected_val_pristine[['id', 'author', 'num_comments', 'class']], \n",
    "                     val_pristine_captioned[['id', 'original_caption', 'generated_caption']], \n",
    "                     on='id', how='inner')\n",
    "\n",
    "result_df = merged_df[['id', 'author', 'original_caption', 'generated_caption', 'num_comments', 'class']]\n",
    "\n",
    "result_df.to_csv(VAL_CAPTIONED_FINAL, index=False)\n",
    "result_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
