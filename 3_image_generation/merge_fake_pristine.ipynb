{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) At this point i merge all the generated synthetic images from all the methods for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#TEST\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_SD.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_DL.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_GL.csv\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_synthetics.csv\", index=False)\n",
    "\n",
    "#VAL\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_SD.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_DL.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_GL.csv\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_synthetics.csv\", index=False)\n",
    "\n",
    "#TRAIN\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_SD.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_DL.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_GL.csv\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_synthetics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i merge, for each set, the csv of the whole images (pristine & fakes) with the csv of the fakes, overwriting with the fake ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/1_dataset_cleaning/csv/train_tsv_with_class2.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_synthetics.csv\")\n",
    "\n",
    "# Merge the two DataFrames on the 'id' column\n",
    "merged_df = pd.merge(df1, df2, on='id', how='outer', suffixes=('_old', ''))\n",
    "\n",
    "# Fill missing values in the first DataFrame with values from the second DataFrame\n",
    "for column in df1.columns:\n",
    "    if column != 'id':\n",
    "        merged_df[column] = merged_df.apply(lambda row: row[column] if pd.notna(row[column]) else row[f'{column}_old'], axis=1)\n",
    "\n",
    "# Drop the columns with '_old' suffix\n",
    "merged_df.drop(columns=[col for col in merged_df.columns if col.endswith('_old')], inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/1_dataset_cleaning/csv/test_tsv_with_class2.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_synthetics.csv\")\n",
    "\n",
    "# Merge the two DataFrames on the 'id' column\n",
    "merged_df = pd.merge(df1, df2, on='id', how='outer', suffixes=('_old', ''))\n",
    "\n",
    "# Fill missing values in the first DataFrame with values from the second DataFrame\n",
    "for column in df1.columns:\n",
    "    if column != 'id':\n",
    "        merged_df[column] = merged_df.apply(lambda row: row[column] if pd.notna(row[column]) else row[f'{column}_old'], axis=1)\n",
    "\n",
    "# Drop the columns with '_old' suffix\n",
    "merged_df.drop(columns=[col for col in merged_df.columns if col.endswith('_old')], inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/1_dataset_cleaning/csv/val_tsv_with_class2.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_synthetics.csv\")\n",
    "\n",
    "# Merge the two DataFrames on the 'id' column\n",
    "merged_df = pd.merge(df1, df2, on='id', how='outer', suffixes=('_old', ''))\n",
    "\n",
    "# Fill missing values in the first DataFrame with values from the second DataFrame\n",
    "for column in df1.columns:\n",
    "    if column != 'id':\n",
    "        merged_df[column] = merged_df.apply(lambda row: row[column] if pd.notna(row[column]) else row[f'{column}_old'], axis=1)\n",
    "\n",
    "# Drop the columns with '_old' suffix\n",
    "merged_df.drop(columns=[col for col in merged_df.columns if col.endswith('_old')], inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Check that the cardinalities are correct after merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i check whether the cardinalities are correct after the substitution of the fake images in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'class' equal to 'fake' in train set: 257125\n",
      "Number of rows with 'class' equal to 'fake' in test set: 26480\n",
      "Number of rows with 'class' equal to 'fake' in val set: 26580\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\")\n",
    "\n",
    "# Count the number of rows where the 'class' column is equal to 'fake'\n",
    "fake_count1 = len(df1[df1['class'] == 'fake'])\n",
    "fake_count2 = len(df2[df2['class'] == 'fake'])\n",
    "fake_count3 = len(df3[df3['class'] == 'fake'])\n",
    "\n",
    "print(\"Number of rows with 'class' equal to 'fake' in train set:\", fake_count1)\n",
    "print(\"Number of rows with 'class' equal to 'fake' in test set:\", fake_count2)\n",
    "print(\"Number of rows with 'class' equal to 'fake' in val set:\", fake_count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are matches between the IDs in the 'id' column and the image filenames.\n",
      "Matched IDs: 100000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "\n",
    "# Filter the DataFrame where 'class' is 'fake' and extract the 'id' values\n",
    "fake_ids_df = set(df[df['class'] == 'fake']['id'])\n",
    "\n",
    "# Path to the folder containing the images\n",
    "folder_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/train\"\n",
    "\n",
    "# Get the list of image filenames from the folder\n",
    "image_filenames = os.listdir(folder_path)\n",
    "\n",
    "# Extract the IDs from the image filenames\n",
    "image_ids = set()\n",
    "for filename in image_filenames:\n",
    "    # Remove the file extension \".jpg\"\n",
    "    filename_without_extension = os.path.splitext(filename)[0]\n",
    "    \n",
    "    parts = filename_without_extension.split(\"_\")\n",
    "    if len(parts) > 2 and parts[0] in ['SD', 'GL', 'DL'] and parts[1] == 'fake':\n",
    "        image_ids.add(parts[2])\n",
    "\n",
    "# Check for matches between the two sets of IDs\n",
    "matched_ids = fake_ids_df.intersection(image_ids)\n",
    "\n",
    "if matched_ids:\n",
    "    print(\"There are matches between the IDs in the 'id' column and the image filenames.\")\n",
    "    print(\"Matched IDs:\", str(len(matched_ids)))\n",
    "else:\n",
    "    print(\"There are no matches between the IDs in the 'id' column and the image filenames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train set: 542996\n",
      "Number of rows in test set: 58047\n",
      "Number of rows in val set: 57489\n",
      "Number tot of rows: 658532\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\")\n",
    "\n",
    "count1 = len(df1)\n",
    "count2 = len(df2)\n",
    "count3 = len(df3)\n",
    "\n",
    "print(\"Number of rows in train set:\", count1)\n",
    "print(\"Number of rows in test set:\", count2)\n",
    "print(\"Number of rows in val set:\", count3)\n",
    "print(\"Number tot of rows:\", str(count1+count2+count3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images missing in the folder but present in train.csv: 100000\n",
      "Images missing in the folder but present in test.csv: 10000\n",
      "Images missing in the folder but present in validation.csv: 10000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def extract_ids_from_filenames(folder_path):\n",
    "    image_filenames = os.listdir(folder_path)\n",
    "    image_ids = set()\n",
    "    for filename in image_filenames:\n",
    "        filename_without_extension = os.path.splitext(filename)[0]\n",
    "        image_id = filename_without_extension\n",
    "        image_ids.add(image_id)\n",
    "    return image_ids\n",
    "\n",
    "def check_ids_in_csv_and_folder(csv_path, folder_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    ids_from_csv = set(df['id'])\n",
    "    ids_from_folder = extract_ids_from_filenames(folder_path)\n",
    "    missing_in_folder = ids_from_csv - ids_from_folder\n",
    "    return missing_in_folder\n",
    "\n",
    "# Paths to CSV files and folder\n",
    "train_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\"\n",
    "test_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\"\n",
    "validation_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\"\n",
    "folder_path = \"C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning\"\n",
    "\n",
    "# Check IDs from train.csv\n",
    "missing_in_folder_train = check_ids_in_csv_and_folder(train_csv_path, folder_path)\n",
    "print(\"Images missing in the folder but present in train.csv:\", len(missing_in_folder_train))\n",
    "\n",
    "# Check IDs from test.csv\n",
    "missing_in_folder_test = check_ids_in_csv_and_folder(test_csv_path, folder_path)\n",
    "print(\"Images missing in the folder but present in test.csv:\", len(missing_in_folder_test))\n",
    "\n",
    "# Check IDs from validation.csv\n",
    "missing_in_folder_validation = check_ids_in_csv_and_folder(validation_csv_path, folder_path)\n",
    "print(\"Images missing in the folder but present in validation.csv:\", len(missing_in_folder_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Merge the pristine and fake ones, deleting the pristine duplicates for the fake ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substituted 100000 images in the train set, 100000 removed\n",
      "Substituted 10000 images in the test set, 10000 removed\n",
      "Substituted 10000 images in the validation set, 10000 removed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_fake_images(source_folder, destination_folder):\n",
    "    substituted_count = 0  # Initialize counter for substituted images\n",
    "    removed=0\n",
    "    # Iterate through the files in the source folder\n",
    "    for filename in os.listdir(source_folder):\n",
    "        # Extract the image ID from the filename\n",
    "        image_id = filename.split(\"_\")[2]\n",
    "        \n",
    "        # Construct the paths for source and destination images\n",
    "        source_image_path = os.path.join(source_folder, filename)\n",
    "        destination_image_path = os.path.join(destination_folder, image_id)\n",
    "        \n",
    "        # If the destination image exists, remove it\n",
    "        if os.path.exists(destination_image_path):\n",
    "            os.remove(destination_image_path) ### PROBLEM\n",
    "            removed += 1  # Increment counter for removed images\n",
    "        \n",
    "        # Copy the fake image to the destination folder\n",
    "        shutil.copy(source_image_path, destination_folder)\n",
    "        substituted_count += 1  # Increment counter for substituted images\n",
    "        \n",
    "    return substituted_count, removed\n",
    "\n",
    "# Paths to the dataset folder and fake image folders\n",
    "dataset_folder = \"C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning\"\n",
    "fake_train_folder = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/train\"\n",
    "fake_test_folder = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/test\"\n",
    "fake_validation_folder = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/validation\"\n",
    "\n",
    "# Copy fake images from the train folder to the dataset folder and print the number of substituted images\n",
    "train_substituted_count, removed = copy_fake_images(fake_train_folder, dataset_folder)\n",
    "print(f\"Substituted {train_substituted_count} images in the train set, {removed} removed\")\n",
    "\n",
    "# Copy fake images from the test folder to the dataset folder and print the number of substituted images\n",
    "test_substituted_count,removed = copy_fake_images(fake_test_folder, dataset_folder)\n",
    "print(f\"Substituted {test_substituted_count} images in the test set, {removed} removed\")\n",
    "\n",
    "# Copy fake images from the validation folder to the dataset folder and print the number of substituted images\n",
    "validation_substituted_count,removed = copy_fake_images(fake_validation_folder, dataset_folder)\n",
    "print(f\"Substituted {validation_substituted_count} images in the validation set, {removed} removed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542996\n",
      "Number of unique images found in the folder: 542996\n",
      "58047\n",
      "Number of unique images found in the folder: 58047\n",
      "57489\n",
      "Number of unique images found in the folder: 57489\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to get unique image IDs from CSV\n",
    "def get_unique_image_ids(csv_file):\n",
    "    unique_image_ids = set()\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # Check if 'generated_caption' column is present and not empty\n",
    "            if 'generated_caption' in row and row['generated_caption']:\n",
    "                unique_image_ids.add(row['fake_id'])\n",
    "            else:\n",
    "                unique_image_ids.add(row['id'])\n",
    "    return list(unique_image_ids)\n",
    "\n",
    "# Function to count images in folder\n",
    "def count_images_in_folder(folder_path, image_ids):\n",
    "    image_count = 0\n",
    "    for image_id in image_ids:\n",
    "        image_file = os.path.join(folder_path, f\"{image_id}.jpg\") \n",
    "        if os.path.isfile(image_file):\n",
    "            image_count += 1\n",
    "    return image_count\n",
    "\n",
    "# Main function\n",
    "def check_train():\n",
    "    csv_file = 'C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv'  \n",
    "    folder_path = 'C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning'  \n",
    "    unique_image_ids = get_unique_image_ids(csv_file)\n",
    "    print(len(unique_image_ids))\n",
    "    num_images_found = count_images_in_folder(folder_path, unique_image_ids)\n",
    "    print(f\"Number of unique images found in the folder: {num_images_found}\")\n",
    "\n",
    "def check_test():\n",
    "    csv_file = 'C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv'  \n",
    "    folder_path = 'C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning'  \n",
    "    unique_image_ids = get_unique_image_ids(csv_file)\n",
    "    print(len(unique_image_ids))\n",
    "    num_images_found = count_images_in_folder(folder_path, unique_image_ids)\n",
    "    print(f\"Number of unique images found in the folder: {num_images_found}\")\n",
    "\n",
    "def check_val():\n",
    "    csv_file = 'C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv'  \n",
    "    folder_path = 'C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning'  \n",
    "    unique_image_ids = get_unique_image_ids(csv_file)\n",
    "    print(len(unique_image_ids))\n",
    "    num_images_found = count_images_in_folder(folder_path, unique_image_ids)\n",
    "    print(f\"Number of unique images found in the folder: {num_images_found}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_train()\n",
    "    check_test()\n",
    "    check_val()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
