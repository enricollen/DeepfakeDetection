{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) At this point i merge all the generated synthetic images from all the methods for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#TEST\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_SD.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_DL.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_GL.csv\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_synthetics.csv\", index=False)\n",
    "\n",
    "#VAL\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_SD.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_DL.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_GL.csv\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_synthetics.csv\", index=False)\n",
    "\n",
    "#TRAIN\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_SD.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_DL.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_GL.csv\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_synthetics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i merge, for each set, the csv of the whole images (pristine & fakes) with the csv of the fakes, overwriting with the fake ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/1_dataset_cleaning/csv/train_tsv_with_class2.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_synthetics.csv\")\n",
    "\n",
    "# Merge the two DataFrames on the 'id' column\n",
    "merged_df = pd.merge(df1, df2, on='id', how='outer', suffixes=('_old', ''))\n",
    "\n",
    "# Fill missing values in the first DataFrame with values from the second DataFrame\n",
    "for column in df1.columns:\n",
    "    if column != 'id':\n",
    "        merged_df[column] = merged_df.apply(lambda row: row[column] if pd.notna(row[column]) else row[f'{column}_old'], axis=1)\n",
    "\n",
    "# Drop the columns with '_old' suffix\n",
    "merged_df.drop(columns=[col for col in merged_df.columns if col.endswith('_old')], inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# TEST\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/1_dataset_cleaning/csv/test_tsv_with_class2.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_synthetics.csv\")\n",
    "\n",
    "# Merge the two DataFrames on the 'id' column\n",
    "merged_df = pd.merge(df1, df2, on='id', how='outer', suffixes=('_old', ''))\n",
    "\n",
    "# Fill missing values in the first DataFrame with values from the second DataFrame\n",
    "for column in df1.columns:\n",
    "    if column != 'id':\n",
    "        merged_df[column] = merged_df.apply(lambda row: row[column] if pd.notna(row[column]) else row[f'{column}_old'], axis=1)\n",
    "\n",
    "# Drop the columns with '_old' suffix\n",
    "merged_df.drop(columns=[col for col in merged_df.columns if col.endswith('_old')], inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\", index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TEST\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/1_dataset_cleaning/csv/test_tsv_with_class2.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_synthetics.csv\")\n",
    "\n",
    "# Ensure that columns in df1 match the columns in df2\n",
    "for column in df2.columns:\n",
    "    if column not in df1.columns:\n",
    "        df1[column] = pd.Series(dtype='object')  # Add missing columns with NaN values\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True, sort=False)\n",
    "reordered_columns = ['id', 'fake_id', 'author', 'original_caption', 'generated_caption', \n",
    "                     'num_comments', '6_way_label', 'real_image', 'fake_image', \n",
    "                     'real_text', 'fakenews_text', 'class']\n",
    "\n",
    "merged_df = merged_df[reordered_columns]\n",
    "\n",
    "# Write the merged dataframe to a new CSV file\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_with_duplicates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# VALIDATION\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/1_dataset_cleaning/csv/val_tsv_with_class2.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_synthetics.csv\")\n",
    "\n",
    "# Merge the two DataFrames on the 'id' column\n",
    "merged_df = pd.merge(df1, df2, on='id', how='outer', suffixes=('_old', ''))\n",
    "\n",
    "# Fill missing values in the first DataFrame with values from the second DataFrame\n",
    "for column in df1.columns:\n",
    "    if column != 'id':\n",
    "        merged_df[column] = merged_df.apply(lambda row: row[column] if pd.notna(row[column]) else row[f'{column}_old'], axis=1)\n",
    "\n",
    "# Drop the columns with '_old' suffix\n",
    "merged_df.drop(columns=[col for col in merged_df.columns if col.endswith('_old')], inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\", index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# VALIDATION\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/1_dataset_cleaning/csv/val_tsv_with_class2.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_synthetics.csv\")\n",
    "\n",
    "# Ensure that columns in df1 match the columns in df2\n",
    "for column in df2.columns:\n",
    "    if column not in df1.columns:\n",
    "        df1[column] = pd.Series(dtype='object')  # Add missing columns with NaN values\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True, sort=False)\n",
    "reordered_columns = ['id', 'fake_id', 'author', 'original_caption', 'generated_caption', \n",
    "                     'num_comments', '6_way_label', 'real_image', 'fake_image', \n",
    "                     'real_text', 'fakenews_text', 'class']\n",
    "\n",
    "merged_df = merged_df[reordered_columns]\n",
    "\n",
    "# Write the merged dataframe to a new CSV file\n",
    "merged_df.to_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_with_duplicates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Check that the cardinalities are correct after merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i check whether the cardinalities are correct after the substitution of the fake images in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'class' equal to 'fake' in train set: 257125\n",
      "Number of rows with 'class' equal to 'fake' in test set: 26480\n",
      "Number of rows with 'class' equal to 'fake' in val set: 26580\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\")\n",
    "\n",
    "# Count the number of rows where the 'class' column is equal to 'fake'\n",
    "fake_count1 = len(df1[df1['class'] == 'fake'])\n",
    "fake_count2 = len(df2[df2['class'] == 'fake'])\n",
    "fake_count3 = len(df3[df3['class'] == 'fake'])\n",
    "\n",
    "print(\"Number of rows with 'class' equal to 'fake' in train set:\", fake_count1)\n",
    "print(\"Number of rows with 'class' equal to 'fake' in test set:\", fake_count2)\n",
    "print(\"Number of rows with 'class' equal to 'fake' in val set:\", fake_count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are matches between the IDs in the 'id' column and the image filenames.\n",
      "Matched IDs: 100000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "\n",
    "# Filter the DataFrame where 'class' is 'fake' and extract the 'id' values\n",
    "fake_ids_df = set(df[df['class'] == 'fake']['id'])\n",
    "\n",
    "# Path to the folder containing the images\n",
    "folder_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/train\"\n",
    "\n",
    "# Get the list of image filenames from the folder\n",
    "image_filenames = os.listdir(folder_path)\n",
    "\n",
    "# Extract the IDs from the image filenames\n",
    "image_ids = set()\n",
    "for filename in image_filenames:\n",
    "    # Remove the file extension \".jpg\"\n",
    "    filename_without_extension = os.path.splitext(filename)[0]\n",
    "    \n",
    "    parts = filename_without_extension.split(\"_\")\n",
    "    if len(parts) > 2 and parts[0] in ['SD', 'GL', 'DL'] and parts[1] == 'fake':\n",
    "        image_ids.add(parts[2])\n",
    "\n",
    "# Check for matches between the two sets of IDs\n",
    "matched_ids = fake_ids_df.intersection(image_ids)\n",
    "\n",
    "if matched_ids:\n",
    "    print(\"There are matches between the IDs in the 'id' column and the image filenames.\")\n",
    "    print(\"Matched IDs:\", str(len(matched_ids)))\n",
    "else:\n",
    "    print(\"There are no matches between the IDs in the 'id' column and the image filenames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train set: 542996\n",
      "Number of rows in test set: 58047\n",
      "Number of rows in val set: 57489\n",
      "Number tot of rows: 658532\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\")\n",
    "\n",
    "count1 = len(df1)\n",
    "count2 = len(df2)\n",
    "count3 = len(df3)\n",
    "\n",
    "print(\"Number of rows in train set:\", count1)\n",
    "print(\"Number of rows in test set:\", count2)\n",
    "print(\"Number of rows in val set:\", count3)\n",
    "print(\"Number tot of rows:\", str(count1+count2+count3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images missing in the folder but present in train.csv: 100000\n",
      "Images missing in the folder but present in test.csv: 10000\n",
      "Images missing in the folder but present in validation.csv: 10000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def extract_ids_from_filenames(folder_path):\n",
    "    image_filenames = os.listdir(folder_path)\n",
    "    image_ids = set()\n",
    "    for filename in image_filenames:\n",
    "        filename_without_extension = os.path.splitext(filename)[0]\n",
    "        image_id = filename_without_extension\n",
    "        image_ids.add(image_id)\n",
    "    return image_ids\n",
    "\n",
    "def check_ids_in_csv_and_folder(csv_path, folder_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    ids_from_csv = set(df['id'])\n",
    "    ids_from_folder = extract_ids_from_filenames(folder_path)\n",
    "    missing_in_folder = ids_from_csv - ids_from_folder\n",
    "    return missing_in_folder\n",
    "\n",
    "# Paths to CSV files and folder\n",
    "train_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\"\n",
    "test_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\"\n",
    "validation_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\"\n",
    "folder_path = \"C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning\"\n",
    "\n",
    "# Check IDs from train.csv\n",
    "missing_in_folder_train = check_ids_in_csv_and_folder(train_csv_path, folder_path)\n",
    "print(\"Images missing in the folder but present in train.csv:\", len(missing_in_folder_train))\n",
    "\n",
    "# Check IDs from test.csv\n",
    "missing_in_folder_test = check_ids_in_csv_and_folder(test_csv_path, folder_path)\n",
    "print(\"Images missing in the folder but present in test.csv:\", len(missing_in_folder_test))\n",
    "\n",
    "# Check IDs from validation.csv\n",
    "missing_in_folder_validation = check_ids_in_csv_and_folder(validation_csv_path, folder_path)\n",
    "print(\"Images missing in the folder but present in validation.csv:\", len(missing_in_folder_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Merge the pristine and fake ones, deleting the pristine duplicates for the fake ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substituted 100000 images in the train set, 100000 removed\n",
      "Substituted 10000 images in the test set, 10000 removed\n",
      "Substituted 10000 images in the validation set, 10000 removed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_fake_images(source_folder, destination_folder):\n",
    "    substituted_count = 0  # Initialize counter for substituted images\n",
    "    removed=0\n",
    "    # Iterate through the files in the source folder\n",
    "    for filename in os.listdir(source_folder):\n",
    "        # Extract the image ID from the filename\n",
    "        image_id = filename.split(\"_\")[2]\n",
    "        \n",
    "        # Construct the paths for source and destination images\n",
    "        source_image_path = os.path.join(source_folder, filename)\n",
    "        destination_image_path = os.path.join(destination_folder, image_id)\n",
    "        \n",
    "        # If the destination image exists, remove it\n",
    "        if os.path.exists(destination_image_path):\n",
    "            os.remove(destination_image_path)\n",
    "            removed += 1  # Increment counter for removed images\n",
    "        \n",
    "        # Copy the fake image to the destination folder\n",
    "        shutil.copy(source_image_path, destination_folder)\n",
    "        substituted_count += 1  # Increment counter for substituted images\n",
    "        \n",
    "    return substituted_count, removed\n",
    "\n",
    "# Paths to the dataset folder and fake image folders\n",
    "dataset_folder = \"C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning\"\n",
    "fake_train_folder = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/train\"\n",
    "fake_test_folder = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/test\"\n",
    "fake_validation_folder = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/validation\"\n",
    "\n",
    "# Copy fake images from the train folder to the dataset folder and print the number of substituted images\n",
    "train_substituted_count, removed = copy_fake_images(fake_train_folder, dataset_folder)\n",
    "print(f\"Substituted {train_substituted_count} images in the train set, {removed} removed\")\n",
    "\n",
    "# Copy fake images from the test folder to the dataset folder and print the number of substituted images\n",
    "test_substituted_count,removed = copy_fake_images(fake_test_folder, dataset_folder)\n",
    "print(f\"Substituted {test_substituted_count} images in the test set, {removed} removed\")\n",
    "\n",
    "# Copy fake images from the validation folder to the dataset folder and print the number of substituted images\n",
    "validation_substituted_count,removed = copy_fake_images(fake_validation_folder, dataset_folder)\n",
    "print(f\"Substituted {validation_substituted_count} images in the validation set, {removed} removed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Check the correctness of the whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542996\n",
      "Number of unique images found in the folder: 542996\n",
      "58047\n",
      "Number of unique images found in the folder: 58047\n",
      "57489\n",
      "Number of unique images found in the folder: 57489\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to get unique image IDs from CSV\n",
    "def get_unique_image_ids(csv_file):\n",
    "    unique_image_ids = set()\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # Check if 'generated_caption' column is present and not empty\n",
    "            if 'generated_caption' in row and row['generated_caption']:\n",
    "                unique_image_ids.add(row['fake_id'])\n",
    "            else:\n",
    "                unique_image_ids.add(row['id'])\n",
    "    return list(unique_image_ids)\n",
    "\n",
    "# Function to count images in folder\n",
    "def count_images_in_folder(folder_path, image_ids):\n",
    "    image_count = 0\n",
    "    for image_id in image_ids:\n",
    "        image_file = os.path.join(folder_path, f\"{image_id}.jpg\") \n",
    "        if os.path.isfile(image_file):\n",
    "            image_count += 1\n",
    "    return image_count\n",
    "\n",
    "# Main function\n",
    "def check_train():\n",
    "    csv_file = 'C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv'  \n",
    "    folder_path = 'C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning'  \n",
    "    unique_image_ids = get_unique_image_ids(csv_file)\n",
    "    print(len(unique_image_ids))\n",
    "    num_images_found = count_images_in_folder(folder_path, unique_image_ids)\n",
    "    print(f\"Number of unique images found in the folder: {num_images_found}\")\n",
    "\n",
    "def check_test():\n",
    "    csv_file = 'C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv'  \n",
    "    folder_path = 'C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning'  \n",
    "    unique_image_ids = get_unique_image_ids(csv_file)\n",
    "    print(len(unique_image_ids))\n",
    "    num_images_found = count_images_in_folder(folder_path, unique_image_ids)\n",
    "    print(f\"Number of unique images found in the folder: {num_images_found}\")\n",
    "\n",
    "def check_val():\n",
    "    csv_file = 'C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv'  \n",
    "    folder_path = 'C:/Users/nello/Desktop/TESI/public_image_set_after_data_cleaning'  \n",
    "    unique_image_ids = get_unique_image_ids(csv_file)\n",
    "    print(len(unique_image_ids))\n",
    "    num_images_found = count_images_in_folder(folder_path, unique_image_ids)\n",
    "    print(f\"Number of unique images found in the folder: {num_images_found}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_train()\n",
    "    check_test()\n",
    "    check_val()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the difference in dataset class cardinalities before and after deepfake generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINALITIES OF ORIGINAL CLASSES WITHOUT FAKES:\n",
      "\n",
      "TRAIN:\n",
      "Label: True                 | Cardinality: 215097\n",
      "Label: Manipulated Content  | Cardinality: 157125\n",
      "Label: False Connection     | Cardinality: 105603\n",
      "Label: Satire               | Cardinality: 32673\n",
      "Label: Misleading Content   | Cardinality: 21117\n",
      "Label: Imposter Content     | Cardinality: 11381\n",
      "\n",
      "TEST:\n",
      "Label: True                 | Cardinality: 23352\n",
      "Label: Manipulated Content  | Cardinality: 16480\n",
      "Label: False Connection     | Cardinality: 11217\n",
      "Label: Satire               | Cardinality: 3504\n",
      "Label: Misleading Content   | Cardinality: 2295\n",
      "Label: Imposter Content     | Cardinality: 1199\n",
      "\n",
      "VALIDATION:\n",
      "Label: True                 | Cardinality: 22981\n",
      "Label: Manipulated Content  | Cardinality: 16580\n",
      "Label: False Connection     | Cardinality: 11116\n",
      "Label: Satire               | Cardinality: 3438\n",
      "Label: Misleading Content   | Cardinality: 2165\n",
      "Label: Imposter Content     | Cardinality: 1209\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\")\n",
    "\n",
    "class_mapping = {\n",
    "    0: \"True\",\n",
    "    1: \"Satire\",\n",
    "    2: \"False Connection\",\n",
    "    3: \"Imposter Content\",\n",
    "    4: \"Manipulated Content\",\n",
    "    5: \"Misleading Content\"\n",
    "}\n",
    "\n",
    "# Map integer class labels to class names for each DataFrame\n",
    "df1[\"6_way_label\"] = df1[\"6_way_label\"].map(class_mapping)\n",
    "df2[\"6_way_label\"] = df2[\"6_way_label\"].map(class_mapping)\n",
    "df3[\"6_way_label\"] = df3[\"6_way_label\"].map(class_mapping)\n",
    "\n",
    "# Calculate the cardinality of each value in the \"6_way_label\" column for each DataFrame\n",
    "label_counts_train = df1[\"6_way_label\"].value_counts()\n",
    "label_counts_test = df2[\"6_way_label\"].value_counts()\n",
    "label_counts_validation = df3[\"6_way_label\"].value_counts()\n",
    "\n",
    "# Print each value and its cardinality for each set\n",
    "print(\"CARDINALITIES OF ORIGINAL CLASSES WITHOUT FAKES:\\n\")\n",
    "print(\"TRAIN:\")\n",
    "for label, count in label_counts_train.items():\n",
    "    print(f\"Label: {str(label).ljust(20)} | Cardinality: {count}\")\n",
    "\n",
    "print(\"\\nTEST:\")\n",
    "for label, count in label_counts_test.items():\n",
    "    print(f\"Label: {str(label).ljust(20)} | Cardinality: {count}\")\n",
    "\n",
    "print(\"\\nVALIDATION:\")\n",
    "for label, count in label_counts_validation.items():\n",
    "    print(f\"Label: {str(label).ljust(20)} | Cardinality: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINALITIES AFTER FAKES GENERATION:\n",
      "\n",
      "\n",
      "TRAIN:\n",
      "Label: True                 | Cardinality: 159487\n",
      "Label: Manipulated Content  | Cardinality: 157125\n",
      "Label: False Connection     | Cardinality: 78264\n",
      "Label: Satire               | Cardinality: 24107\n",
      "Label: Misleading Content   | Cardinality: 15552\n",
      "Label: Imposter Content     | Cardinality: 8461\n",
      "Label: Synthetic Generated | Cardinality: 100000\n",
      "\n",
      "\n",
      "TEST:\n",
      "Label: True                 | Cardinality: 17674\n",
      "Label: Manipulated Content  | Cardinality: 16480\n",
      "Label: False Connection     | Cardinality: 8639\n",
      "Label: Satire               | Cardinality: 2643\n",
      "Label: Misleading Content   | Cardinality: 1701\n",
      "Label: Imposter Content     | Cardinality: 910\n",
      "Label: Synthetic Generated | Cardinality: 10000\n",
      "\n",
      "\n",
      "VALIDATION:\n",
      "Label: True                 | Cardinality: 17379\n",
      "Label: Manipulated Content  | Cardinality: 16580\n",
      "Label: False Connection     | Cardinality: 8420\n",
      "Label: Satire               | Cardinality: 2548\n",
      "Label: Misleading Content   | Cardinality: 1645\n",
      "Label: Imposter Content     | Cardinality: 917\n",
      "Label: Synthetic Generated | Cardinality: 10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\")\n",
    "\n",
    "class_mapping = {\n",
    "    0: \"True\",\n",
    "    1: \"Satire\",\n",
    "    2: \"False Connection\",\n",
    "    3: \"Imposter Content\",\n",
    "    4: \"Manipulated Content\",\n",
    "    5: \"Misleading Content\"\n",
    "}\n",
    "\n",
    "# Map integer class labels to class names for each DataFrame\n",
    "df1[\"6_way_label\"] = df1[\"6_way_label\"].map(class_mapping)\n",
    "df2[\"6_way_label\"] = df2[\"6_way_label\"].map(class_mapping)\n",
    "df3[\"6_way_label\"] = df3[\"6_way_label\"].map(class_mapping)\n",
    "\n",
    "# Initialize counters for each set\n",
    "synthetic_generated_train = 0\n",
    "synthetic_generated_test = 0\n",
    "synthetic_generated_validation = 0\n",
    "\n",
    "# Iterate through the \"fake_id\" column for each DataFrame and count the occurrences\n",
    "print(\"CARDINALITIES AFTER FAKES GENERATION:\")\n",
    "for i, df in enumerate([df1, df2, df3]):\n",
    "    synthetic_generated_count = df[df[\"fake_id\"].notna()].shape[0]\n",
    "    label_counts = df[\"6_way_label\"].value_counts()\n",
    "\n",
    "    # Decrement the count for the respective class label if \"fake_id\" is not empty\n",
    "    for label, count in label_counts.items():\n",
    "        synthetic_generated_in_class = df[(df[\"6_way_label\"] == label) & (df[\"fake_id\"].notna())].shape[0]\n",
    "        label_counts[label] -= synthetic_generated_in_class\n",
    "\n",
    "    # Determine the set name based on the index of the loop\n",
    "    set_name = \"TRAIN\" if i == 0 else \"TEST\" if i == 1 else \"VALIDATION\"\n",
    "\n",
    "    # Print each value and its cardinality for each set\n",
    "    print(f\"\\n\\n{set_name}:\")\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"Label: {str(label).ljust(20)} | Cardinality: {count}\")\n",
    "\n",
    "    # Print the count for Synthetic Generated\n",
    "    print(f\"Label: Synthetic Generated | Cardinality: {synthetic_generated_count}\")\n",
    "\n",
    "    # Update the total count for Synthetic Generated for each set\n",
    "    if i == 0:\n",
    "        synthetic_generated_train = synthetic_generated_count\n",
    "    elif i == 1:\n",
    "        synthetic_generated_test = synthetic_generated_count\n",
    "    elif i == 2:\n",
    "        synthetic_generated_validation = synthetic_generated_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the number of fake images generated, distinguishing from fake images + real text and fake images + fakenews text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set:\n",
      "Label: REAL IMAGE + REAL TEXT, Cardinality: 55610\n",
      "Label: REAL IMAGE + FAKENEWS TEXT, Cardinality: 44390\n",
      "\n",
      "Test set:\n",
      "Label: REAL IMAGE + REAL TEXT, Cardinality: 5678\n",
      "Label: REAL IMAGE + FAKENEWS TEXT, Cardinality: 4322\n",
      "\n",
      "Validation set:\n",
      "Label: REAL IMAGE + REAL TEXT, Cardinality: 5602\n",
      "Label: REAL IMAGE + FAKENEWS TEXT, Cardinality: 4398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nello\\AppData\\Local\\Temp\\ipykernel_25872\\3956035921.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"6_way_label\"] = filtered_df[\"6_way_label\"].map(class_mapping)\n",
      "C:\\Users\\nello\\AppData\\Local\\Temp\\ipykernel_25872\\3956035921.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"6_way_label\"] = filtered_df[\"6_way_label\"].map(class_mapping)\n",
      "C:\\Users\\nello\\AppData\\Local\\Temp\\ipykernel_25872\\3956035921.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"6_way_label\"] = filtered_df[\"6_way_label\"].map(class_mapping)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files for train, test, and validation sets\n",
    "df_train = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "df_test = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test.csv\")\n",
    "df_validation = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation.csv\")\n",
    "\n",
    "# Define the class mapping dictionary\n",
    "class_mapping = {\n",
    "    0: \"REAL IMAGE + REAL TEXT\",\n",
    "    1: \"REAL IMAGE + FAKENEWS TEXT\",\n",
    "    2: \"REAL IMAGE + FAKENEWS TEXT\",\n",
    "    3: \"REAL IMAGE + FAKENEWS TEXT\",\n",
    "    4: \"Manipulated Content\",  # exclude class 4 from this aggregation\n",
    "    5: \"REAL IMAGE + FAKENEWS TEXT\"\n",
    "}\n",
    "\n",
    "# Function to print aggregated cardinality\n",
    "def print_aggregated_cardinality(df, label):\n",
    "    # Filter the DataFrame to include only rows where \"fake_id\" is not empty\n",
    "    filtered_df = df[df[\"fake_id\"].notna()]\n",
    "\n",
    "    # Map integer class labels to class names based on the defined class mapping for the filtered DataFrame\n",
    "    filtered_df[\"6_way_label\"] = filtered_df[\"6_way_label\"].map(class_mapping)\n",
    "\n",
    "    # Calculate the cardinality of the values in the \"6_way_label\" column for the filtered DataFrame\n",
    "    label_counts = filtered_df[\"6_way_label\"].value_counts()\n",
    "\n",
    "    # Print the aggregated cardinality of each mapped value in the \"6_way_label\" column for rows with non-empty \"fake_id\" = synthetic images\n",
    "    print(f\"\\n{label} set:\")\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"Label: {label}, Cardinality: {count}\")\n",
    "\n",
    "# Print aggregated cardinality for train, test, and validation sets\n",
    "print_aggregated_cardinality(df_train, \"Training\")\n",
    "print_aggregated_cardinality(df_test, \"Test\")\n",
    "print_aggregated_cardinality(df_validation, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the number of images belonging to class 4 (Manipulated Content):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'class' column = 'fake' and 'fake_id' column empty: 157125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "\n",
    "# Filter the DataFrame based on the conditions\n",
    "rows_with_fake_but_empty_fake_id = df[(df[\"class\"] == \"fake\") & (df[\"fake_id\"].isna())]\n",
    "\n",
    "# Get the number of rows\n",
    "num_rows = len(rows_with_fake_but_empty_fake_id)\n",
    "\n",
    "print(\"Number of rows with 'class' column = 'fake' and 'fake_id' column empty:\", num_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the cardinalities in the version with test and validation set with duplicates (pristine images + fake correspondent both maintained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINALITIES OF ORIGINAL CLASSES WITHOUT FAKES:\n",
      "\n",
      "TRAIN:\n",
      "Label: True                 | Cardinality: 215097\n",
      "Label: Manipulated Content  | Cardinality: 157125\n",
      "Label: False Connection     | Cardinality: 105603\n",
      "Label: Satire               | Cardinality: 32673\n",
      "Label: Misleading Content   | Cardinality: 21117\n",
      "Label: Imposter Content     | Cardinality: 11381\n",
      "\n",
      "TEST:\n",
      "Label: True                 | Cardinality: 29030\n",
      "Label: Manipulated Content  | Cardinality: 16480\n",
      "Label: False Connection     | Cardinality: 13795\n",
      "Label: Satire               | Cardinality: 4365\n",
      "Label: Misleading Content   | Cardinality: 2889\n",
      "Label: Imposter Content     | Cardinality: 1488\n",
      "\n",
      "VALIDATION:\n",
      "Label: True                 | Cardinality: 28583\n",
      "Label: Manipulated Content  | Cardinality: 16580\n",
      "Label: False Connection     | Cardinality: 13812\n",
      "Label: Satire               | Cardinality: 4328\n",
      "Label: Misleading Content   | Cardinality: 2685\n",
      "Label: Imposter Content     | Cardinality: 1501\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_with_duplicates.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_with_duplicates.csv\")\n",
    "\n",
    "class_mapping = {\n",
    "    0: \"True\",\n",
    "    1: \"Satire\",\n",
    "    2: \"False Connection\",\n",
    "    3: \"Imposter Content\",\n",
    "    4: \"Manipulated Content\",\n",
    "    5: \"Misleading Content\"\n",
    "}\n",
    "\n",
    "# Map integer class labels to class names for each DataFrame\n",
    "df1[\"6_way_label\"] = df1[\"6_way_label\"].map(class_mapping)\n",
    "df2[\"6_way_label\"] = df2[\"6_way_label\"].map(class_mapping)\n",
    "df3[\"6_way_label\"] = df3[\"6_way_label\"].map(class_mapping)\n",
    "\n",
    "# Calculate the cardinality of each value in the \"6_way_label\" column for each DataFrame\n",
    "label_counts_train = df1[\"6_way_label\"].value_counts()\n",
    "label_counts_test = df2[\"6_way_label\"].value_counts()\n",
    "label_counts_validation = df3[\"6_way_label\"].value_counts()\n",
    "\n",
    "# Print each value and its cardinality for each set\n",
    "print(\"CARDINALITIES OF ORIGINAL CLASSES WITHOUT FAKES:\\n\")\n",
    "print(\"TRAIN:\")\n",
    "for label, count in label_counts_train.items():\n",
    "    print(f\"Label: {str(label).ljust(20)} | Cardinality: {count}\")\n",
    "\n",
    "print(\"\\nTEST:\")\n",
    "for label, count in label_counts_test.items():\n",
    "    print(f\"Label: {str(label).ljust(20)} | Cardinality: {count}\")\n",
    "\n",
    "print(\"\\nVALIDATION:\")\n",
    "for label, count in label_counts_validation.items():\n",
    "    print(f\"Label: {str(label).ljust(20)} | Cardinality: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
