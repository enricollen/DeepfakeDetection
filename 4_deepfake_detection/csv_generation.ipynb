{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Adapt the csv of the 3 sets for the training phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each set will have a csv with 3 column:\n",
    "- id (containing either the real or fake id)\n",
    "- caption (containing the original caption associated to the post)\n",
    "- class (0 if image pristine, 1 if fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to CSV files for train, test, and validation datasets from the previous phase\n",
    "train_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train.csv\"\n",
    "test_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/test_with_duplicates.csv\"\n",
    "validation_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/validation_with_duplicates.csv\"\n",
    "\n",
    "adapted_train_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/4_deepfake_detection/csv/train.csv\"\n",
    "adapted_test_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/4_deepfake_detection/csv/test.csv\"\n",
    "adapted_val_csv_path = \"C:/Users/nello/Documents/vscode_projects/Thesis/4_deepfake_detection/csv/validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_csv(csv_path, output_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    # Fill the 'id' column based on the condition\n",
    "    new_df['id'] = df['fake_id'].fillna(df['id'])\n",
    "\n",
    "    # Fill the 'class' column based on the condition\n",
    "    new_df['class'] = df['class'].apply(lambda x: 0 if x == 'pristine' else 1)\n",
    "\n",
    "    # Copy the 'original_caption' column\n",
    "    new_df['original_caption'] = df['original_caption']\n",
    "\n",
    "    # Reorder columns\n",
    "    new_df = new_df[['id', 'original_caption', 'class']]\n",
    "\n",
    "    # Shuffle\n",
    "    new_df = new_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    new_df.to_csv(output_path, index=False)\n",
    "\n",
    "# train\n",
    "process_csv(train_csv_path, adapted_train_csv_path)\n",
    "\n",
    "# test\n",
    "process_csv(test_csv_path, adapted_test_csv_path)\n",
    "\n",
    "# validation\n",
    "process_csv(validation_csv_path, adapted_val_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
