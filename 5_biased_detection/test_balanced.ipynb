{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a csv containing all the pristines + truthful text (class 0) and another one with pristine + fake news (class 1,2,3,5), this is the starting point to generate the fakes for generated images +  truthful text and generated images + fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/enriconello/DeepFakeDetection/Thesis/5_biased_detection/csv/test/test.csv\")\n",
    "\n",
    "filtered_df = df[(df['generated_image'] == 0) & (df['real_text'] == 1)]\n",
    "\n",
    "filtered_df.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_to_be_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/enriconello/DeepFakeDetection/Thesis/5_biased_detection/csv/test/test.csv\")\n",
    "\n",
    "filtered_df = df[(df['generated_image'] == 0) & (df['real_text'] == 0)]\n",
    "\n",
    "filtered_df.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_to_be_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i need to caption the images listed in the 2 csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After image captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean the buggy caption starting with \"arafed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of updated rows: 6546\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "original_df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_captioned.csv')\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "modified_df = original_df.copy()\n",
    "\n",
    "# Remove words starting with \"araf\" in the \"generated_caption\" column\n",
    "modified_df['generated_caption'] = modified_df['generated_caption'].str.replace(r'\\baraf\\w*\\b', '', regex=True)\n",
    "\n",
    "# Remove leading and trailing whitespace from the \"generated_caption\" column\n",
    "modified_df['generated_caption'] = modified_df['generated_caption'].str.strip()\n",
    "\n",
    "# Save the modified DataFrame to the same CSV file\n",
    "modified_df.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_captioned.csv\", index=False)\n",
    "\n",
    "# Count the number of updated rows\n",
    "updated_rows_count = (original_df['generated_caption'] != modified_df['generated_caption']).sum()\n",
    "\n",
    "print(f\"Number of updated rows: {updated_rows_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of updated rows: 3533\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "original_df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_captioned.csv')\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "modified_df = original_df.copy()\n",
    "\n",
    "# Remove words starting with \"araf\" in the \"generated_caption\" column\n",
    "modified_df['generated_caption'] = modified_df['generated_caption'].str.replace(r'\\baraf\\w*\\b', '', regex=True)\n",
    "\n",
    "# Remove leading and trailing whitespace from the \"generated_caption\" column\n",
    "modified_df['generated_caption'] = modified_df['generated_caption'].str.strip()\n",
    "\n",
    "# Save the modified DataFrame to the same CSV file\n",
    "modified_df.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_captioned.csv\", index=False)\n",
    "\n",
    "# Count the number of updated rows\n",
    "updated_rows_count = (original_df['generated_caption'] != modified_df['generated_caption']).sum()\n",
    "\n",
    "print(f\"Number of updated rows: {updated_rows_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i generate the fake images for class 0 (23k) and class 1,2,3,5 (18k) starting from the captioned csv and the folder test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After fake generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a csv called test_class_0_final.csv and test_class_1_2_3_5_final.csv, starting from the test_class_0_to_be_generated and test_class_1_2_3_5_to_be_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_to_be_generated.csv\")\n",
    "\n",
    "# new column 'fake_id'\n",
    "df['fake_id'] = ''\n",
    "\n",
    "# assign values to 'fake_id' based on row index intervals\n",
    "df.loc[df.index < 9000, 'fake_id'] = 'SD_fake_' + df['id']\n",
    "df.loc[(df.index >= 9000) & (df.index < 18000), 'fake_id'] = 'DL_fake_' + df['id']\n",
    "df.loc[df.index >= 18000, 'fake_id'] = 'GL_fake_' + df['id']\n",
    "\n",
    "# 'fake_id' column next to 'id' column\n",
    "df.insert(df.columns.get_loc('id') + 1, 'fake_id', df.pop('fake_id'))\n",
    "\n",
    "df.to_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_to_be_generated.csv\")\n",
    "\n",
    "# new column 'fake_id'\n",
    "df['fake_id'] = ''\n",
    "\n",
    "# assign values to 'fake_id' based on row index intervals\n",
    "df.loc[df.index < 7000, 'fake_id'] = 'SD_fake_' + df['id']\n",
    "df.loc[(df.index >= 7000) & (df.index < 14000), 'fake_id'] = 'DL_fake_' + df['id']\n",
    "df.loc[df.index >= 14000, 'fake_id'] = 'GL_fake_' + df['id']\n",
    "\n",
    "# 'fake_id' column next to 'id' column\n",
    "df.insert(df.columns.get_loc('id') + 1, 'fake_id', df.pop('fake_id'))\n",
    "\n",
    "df.to_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the column pristine_image = 0 and generated_image = 1 for every row in test_class_0_final csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_final.csv')\n",
    "\n",
    "# Swap the values of the two columns\n",
    "df['pristine_image'], df['generated_image'] = df['generated_image'], df['pristine_image']\n",
    "\n",
    "df.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_final.csv')\n",
    "\n",
    "# Swap the values of the two columns\n",
    "df['pristine_image'], df['generated_image'] = df['generated_image'], df['pristine_image']\n",
    "\n",
    "df.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i need to add the column \"generated_caption\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake_id</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>generated_caption</th>\n",
       "      <th>6_way_label</th>\n",
       "      <th>pristine_image</th>\n",
       "      <th>generated_image</th>\n",
       "      <th>real_text</th>\n",
       "      <th>fakenews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d2le0</td>\n",
       "      <td>SD_fake_1d2le0</td>\n",
       "      <td>bird about to eat a cherry</td>\n",
       "      <td>bird with a berry in its beak sitting on a tre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hwppu</td>\n",
       "      <td>SD_fake_hwppu</td>\n",
       "      <td>sometimes i feel like my coffee is watching me</td>\n",
       "      <td>there is a cup of coffee on a table with a cel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>axq43x</td>\n",
       "      <td>SD_fake_axq43x</td>\n",
       "      <td>elixir of immortality found in central chinas ...</td>\n",
       "      <td>there are many vases and jars on a table with ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b6p6px</td>\n",
       "      <td>SD_fake_b6p6px</td>\n",
       "      <td>instant oxidation steel wool and vinegar on wo...</td>\n",
       "      <td>a close up of a wooden floor with a wooden flo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>403yxi</td>\n",
       "      <td>SD_fake_403yxi</td>\n",
       "      <td>homeless veterans in riverside now have place ...</td>\n",
       "      <td>valley news logo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         fake_id                                   original_caption  \\\n",
       "0  1d2le0  SD_fake_1d2le0                         bird about to eat a cherry   \n",
       "1   hwppu   SD_fake_hwppu     sometimes i feel like my coffee is watching me   \n",
       "2  axq43x  SD_fake_axq43x  elixir of immortality found in central chinas ...   \n",
       "3  b6p6px  SD_fake_b6p6px  instant oxidation steel wool and vinegar on wo...   \n",
       "4  403yxi  SD_fake_403yxi  homeless veterans in riverside now have place ...   \n",
       "\n",
       "                                   generated_caption  6_way_label  \\\n",
       "0  bird with a berry in its beak sitting on a tre...            0   \n",
       "1  there is a cup of coffee on a table with a cel...            0   \n",
       "2  there are many vases and jars on a table with ...            0   \n",
       "3  a close up of a wooden floor with a wooden flo...            0   \n",
       "4                                   valley news logo            0   \n",
       "\n",
       "   pristine_image  generated_image  real_text  fakenews_text  \n",
       "0               0                1          1              0  \n",
       "1               0                1          1              0  \n",
       "2               0                1          1              0  \n",
       "3               0                1          1              0  \n",
       "4               0                1          1              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_a = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_final.csv\")\n",
    "df_b = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_captioned.csv\")\n",
    "\n",
    "# Perform inner join on 'id' column\n",
    "df_c = pd.merge(df_a, df_b, on='id', how='inner')\n",
    "\n",
    "# Rename 'original_caption_x' to 'original_caption'\n",
    "df_c = df_c.rename(columns={'original_caption_x': 'original_caption'})\n",
    "\n",
    "df_c = df_c[['id', 'fake_id', 'original_caption', 'generated_caption', '6_way_label', 'pristine_image', 'generated_image', 'real_text', 'fakenews_text']]\n",
    "\n",
    "df_c.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_final.csv\", index=False)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake_id</th>\n",
       "      <th>original_caption</th>\n",
       "      <th>generated_caption</th>\n",
       "      <th>6_way_label</th>\n",
       "      <th>pristine_image</th>\n",
       "      <th>generated_image</th>\n",
       "      <th>real_text</th>\n",
       "      <th>fakenews_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cfyoth</td>\n",
       "      <td>SD_fake_cfyoth</td>\n",
       "      <td>john lennon before meeting paul mccartney live...</td>\n",
       "      <td>a close up of a tweet with a text message</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b3n8a</td>\n",
       "      <td>SD_fake_3b3n8a</td>\n",
       "      <td>the happiest little moon rover from audis inst...</td>\n",
       "      <td>image of a small robot on a surface with rocks</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7l1beq</td>\n",
       "      <td>SD_fake_7l1beq</td>\n",
       "      <td>hydrooxycoumarin murderers adulterers madmen</td>\n",
       "      <td>a close up of a young boy with a black background</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ahq8i</td>\n",
       "      <td>SD_fake_8ahq8i</td>\n",
       "      <td>little penguin in spaaaace</td>\n",
       "      <td>painting of a cat looking out a window at a pl...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8koo4p</td>\n",
       "      <td>SD_fake_8koo4p</td>\n",
       "      <td>hadzhidimovo all wrong bear</td>\n",
       "      <td>photograph of a woman in a tutu and a hat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         fake_id                                   original_caption  \\\n",
       "0  cfyoth  SD_fake_cfyoth  john lennon before meeting paul mccartney live...   \n",
       "1  3b3n8a  SD_fake_3b3n8a  the happiest little moon rover from audis inst...   \n",
       "2  7l1beq  SD_fake_7l1beq       hydrooxycoumarin murderers adulterers madmen   \n",
       "3  8ahq8i  SD_fake_8ahq8i                         little penguin in spaaaace   \n",
       "4  8koo4p  SD_fake_8koo4p                        hadzhidimovo all wrong bear   \n",
       "\n",
       "                                   generated_caption  6_way_label  \\\n",
       "0          a close up of a tweet with a text message            2   \n",
       "1     image of a small robot on a surface with rocks            2   \n",
       "2  a close up of a young boy with a black background            1   \n",
       "3  painting of a cat looking out a window at a pl...            2   \n",
       "4          photograph of a woman in a tutu and a hat            1   \n",
       "\n",
       "   pristine_image  generated_image  real_text  fakenews_text  \n",
       "0               0                1          0              1  \n",
       "1               0                1          0              1  \n",
       "2               0                1          0              1  \n",
       "3               0                1          0              1  \n",
       "4               0                1          0              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_a = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_final.csv\")\n",
    "df_b = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_captioned.csv\")\n",
    "\n",
    "# Perform inner join on 'id' column\n",
    "df_c = pd.merge(df_a, df_b, on='id', how='inner')\n",
    "\n",
    "# Rename 'original_caption_x' to 'original_caption'\n",
    "df_c = df_c.rename(columns={'original_caption_x': 'original_caption'})\n",
    "\n",
    "df_c = df_c[['id', 'fake_id', 'original_caption', 'generated_caption', '6_way_label', 'pristine_image', 'generated_image', 'real_text', 'fakenews_text']]\n",
    "\n",
    "df_c.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_final.csv\", index=False)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally merge test_class_0_final and test_class_1_2_3_5_final to create test_generated_final csv that contains all the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_final.csv\")\n",
    "df2 = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_final.csv\")\n",
    "\n",
    "# Concatenate DataFrames\n",
    "df_union = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df_union.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_generated_final.csv\", index=False)\n",
    "print(len(df_union))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the cardinalities of the classes with the generation methods associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for '6_way_label' 0:\n",
      "Starts with 'SD': 9000\n",
      "Starts with 'GL': 5352\n",
      "Starts with 'DL': 9000\n",
      "\n",
      "Counts for '6_way_label' 1:\n",
      "Starts with 'SD': 1336\n",
      "Starts with 'GL': 832\n",
      "Starts with 'DL': 1336\n",
      "\n",
      "Counts for '6_way_label' 2:\n",
      "Starts with 'SD': 4267\n",
      "Starts with 'GL': 2606\n",
      "Starts with 'DL': 4344\n",
      "\n",
      "Counts for '6_way_label' 3:\n",
      "Starts with 'SD': 472\n",
      "Starts with 'GL': 283\n",
      "Starts with 'DL': 444\n",
      "\n",
      "Counts for '6_way_label' 5:\n",
      "Starts with 'SD': 925\n",
      "Starts with 'GL': 494\n",
      "Starts with 'DL': 876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_generated_final.csv')\n",
    "\n",
    "# Group the DataFrame by '6_way_label'\n",
    "grouped = df.groupby('6_way_label')\n",
    "\n",
    "# Iterate over each group\n",
    "for label, group in grouped:\n",
    "    # Filter the group where 'id' column starts with \"SD\", \"GL\", or \"DL\"\n",
    "    sd_count = len(group[group['fake_id'].str.startswith('SD')])\n",
    "    gl_count = len(group[group['fake_id'].str.startswith('GL')])\n",
    "    dl_count = len(group[group['fake_id'].str.startswith('DL')])\n",
    "    \n",
    "    # Print counts for each value of '6_way_label'\n",
    "    print(f\"Counts for '6_way_label' {label}:\")\n",
    "    print(f\"Starts with 'SD': {sd_count}\")\n",
    "    print(f\"Starts with 'GL': {gl_count}\")\n",
    "    print(f\"Starts with 'DL': {dl_count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i need to merge test_class_0_to_be_generated and test_class_1_2_3_5_to_be_generated to make test_pristine_final csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_0_to_be_generated.csv\")\n",
    "df2 = pd.read_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_class_1_2_3_5_to_be_generated.csv\")\n",
    "\n",
    "# Concatenate DataFrames\n",
    "df_union = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df_union.to_csv(\"/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_pristine_final.csv\", index=False)\n",
    "print(len(df_union))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally i need to merge the test_pristine_final with test_generated_final to generate test csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83134\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_a = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_generated_final.csv')\n",
    "df_b = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_pristine_final.csv')\n",
    "\n",
    "# Add missing columns from A to B with empty values\n",
    "for column in df_a.columns:\n",
    "    if column not in df_b.columns:\n",
    "        df_b[column] = ''\n",
    "\n",
    "# Concatenate dataframes\n",
    "df_c = pd.concat([df_a, df_b])\n",
    "\n",
    "print(len(df_c))\n",
    "df_c.to_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore \"class\" column that is 0 if column pristine_image == 1, else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3145584/2386987533.py:3: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test.csv')\n",
    "\n",
    "# Set 'class' column to 0 where 'pristine_image' column is equal to 1, else set it to 1\n",
    "df['class'] = df.apply(lambda row: 0 if row['pristine_image'] == 1 else 1, axis=1)\n",
    "\n",
    "df.to_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a single column \"id\" that contains either the id or the fake_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV A into a DataFrame\n",
    "df_a = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test.csv')\n",
    "\n",
    "# Create a new DataFrame based on df_a without the 'fake_id' column\n",
    "df_b = df_a.drop(columns=['fake_id'])\n",
    "\n",
    "# Replace the 'id' values with 'fake_id' values where 'fake_id' is not empty\n",
    "df_b['id'] = df_a['fake_id'].fillna(df_a['id'])\n",
    "\n",
    "# Write DataFrame B to a new CSV file\n",
    "df_b.to_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3145584/3826127905.py:3: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test.csv')\n",
    "\n",
    "# Shuffle the rows of the DataFrame\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_shuffled.to_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test image folder reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy the pristine image from dataset_new/test to dataset_new/test_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41567 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41567/41567 [00:10<00:00, 4083.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images copied: 41567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_pristine_final.csv')\n",
    "\n",
    "source_folder = '/home/enriconello/DeepFakeDetection/dataset_new/test'\n",
    "destination_folder = '/home/enriconello/DeepFakeDetection/dataset_new/test_balanced'\n",
    "\n",
    "count = 0\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    image_name = row['id'] + \".jpg\"  \n",
    "    \n",
    "    source_path = os.path.join(source_folder, image_name)\n",
    "    destination_path = os.path.join(destination_folder, image_name)\n",
    "    \n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print(\"Total images copied:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy the generated images from generated_images/class_0 and generated_images/class_1_2_3_5 to dataset_new/test_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images copied: 18215\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_folder = '/home/enriconello/DeepFakeDetection/test_balanced_2/generated_images/class_1_2_3_5'\n",
    "destination_folder = '/home/enriconello/DeepFakeDetection/dataset_new/test_balanced'\n",
    "\n",
    "count = 0\n",
    "\n",
    "for filename in os.listdir(source_folder):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "        \n",
    "        shutil.copyfile(source_path, destination_path)\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "print(\"Total images copied:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show distribution among different generative methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for '6_way_label' 0:\n",
      "Starts with 'SD': 9000\n",
      "Starts with 'GL': 5352\n",
      "Starts with 'DL': 9000\n",
      "\n",
      "Counts for '6_way_label' 1:\n",
      "Starts with 'SD': 1336\n",
      "Starts with 'GL': 832\n",
      "Starts with 'DL': 1336\n",
      "\n",
      "Counts for '6_way_label' 2:\n",
      "Starts with 'SD': 4267\n",
      "Starts with 'GL': 2606\n",
      "Starts with 'DL': 4344\n",
      "\n",
      "Counts for '6_way_label' 3:\n",
      "Starts with 'SD': 472\n",
      "Starts with 'GL': 283\n",
      "Starts with 'DL': 444\n",
      "\n",
      "Counts for '6_way_label' 5:\n",
      "Starts with 'SD': 925\n",
      "Starts with 'GL': 494\n",
      "Starts with 'DL': 876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/enriconello/DeepFakeDetection/test_balanced_2/csv/test_generated_final.csv')\n",
    "\n",
    "# Group the DataFrame by '6_way_label'\n",
    "grouped = df.groupby('6_way_label')\n",
    "\n",
    "# Iterate over each group\n",
    "for label, group in grouped:\n",
    "    # Filter the group where 'id' column starts with \"SD\", \"GL\", or \"DL\"\n",
    "    sd_count = len(group[group['fake_id'].str.startswith('SD')])\n",
    "    gl_count = len(group[group['fake_id'].str.startswith('GL')])\n",
    "    dl_count = len(group[group['fake_id'].str.startswith('DL')])\n",
    "    \n",
    "    # Print counts for each value of '6_way_label'\n",
    "    print(f\"Counts for '6_way_label' {label}:\")\n",
    "    print(f\"Starts with 'SD': {sd_count}\")\n",
    "    print(f\"Starts with 'GL': {gl_count}\")\n",
    "    print(f\"Starts with 'DL': {dl_count}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
