{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55610\n",
      "Filtered IDs saved to train_class_0_already_generated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_synthetics.csv')\n",
    "\n",
    "# Filter rows where '6_way_label' equals 0 and 'fake_id' starts with 'SD', 'DL', or 'GL'\n",
    "filtered_rows_SD = df[(df['6_way_label'] == 0) & (df['fake_id'].str.startswith('SD'))]\n",
    "filtered_rows_DL = df[(df['6_way_label'] == 0) & (df['fake_id'].str.startswith('DL'))]\n",
    "filtered_rows_GL = df[(df['6_way_label'] == 0) & (df['fake_id'].str.startswith('GL'))]\n",
    "\n",
    "# Concatenate columns for all groups\n",
    "result = pd.concat([filtered_rows_SD, filtered_rows_DL, filtered_rows_GL])\n",
    "print(len(result))\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result.to_csv('csv/train_class_0_already_generated.csv', index=False)\n",
    "\n",
    "print(\"Filtered IDs saved to train_class_0_already_generated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN CLASS 0: collect the 55k fakes already generated, and save a csv for the 107k pristine and the 107k-55k to be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train_class_0_already_generated: 55610\n",
      "len of train_pristine: 107548\n",
      "len of train_class_0_to_be_generated: 51939\n",
      "train_class_0_already_generated: 55.610 + train_class_0_to_be_generated: 51.938 = 107548\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MULTIMODAL_TRAIN_CLEANED_WITH_CLASS_TSV = \"C:/Users/nello/OneDrive - University of Pisa/TESI/TSV_JSON/1_dataset_cleaning/tsv/train_tsv_with_class.tsv\"\n",
    "ALREADY_GENERATED_FROM_CLASS_0 = \"csv/train_class_0_already_generated.csv\"\n",
    "\n",
    "train = pd.read_csv(MULTIMODAL_TRAIN_CLEANED_WITH_CLASS_TSV, sep='\\t')\n",
    "train_filtered = train[train['6_way_label'] == 0]\n",
    "\n",
    "train_class_0_already_generated = pd.read_csv(ALREADY_GENERATED_FROM_CLASS_0)\n",
    "print(\"len of train_class_0_already_generated: \"+str(len(train_class_0_already_generated)))\n",
    "\n",
    "# Filter rows from train DataFrame that are not in the 'id' column of the other DataFrame\n",
    "train_not_in_other = train_filtered[~train_filtered['id'].isin(train_class_0_already_generated['id'])]\n",
    "\n",
    "# Select the first 107,549 rows from train_not_in_other\n",
    "train_pristine = train_not_in_other.head(107548)\n",
    "\n",
    "# Save train_pristine to CSV\n",
    "print(\"len of train_pristine: \"+str(len(train_pristine)))\n",
    "train_pristine.to_csv('csv/train_pristine.csv', index=False)\n",
    "\n",
    "# Filter rows from train_filtered that are not in train_class_0_already_generated or train_pristine\n",
    "train_remaining = train_filtered[~train_filtered['id'].isin(train_class_0_already_generated['id']) & ~train_filtered['id'].isin(train_pristine['id'])]\n",
    "\n",
    "# Save the remaining rows to a new CSV file\n",
    "print(\"len of train_class_0_to_be_generated: \"+str(len(train_remaining)))\n",
    "train_remaining.to_csv('csv/train_class_0_to_be_generated.csv', index=False)\n",
    "print(\"train_class_0_already_generated: 55.610 + train_class_0_to_be_generated: 51.938 = \" + str(55610+51938))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename the columns real_image and fake_image to pristine_image and generated_image inside train_class_0_already_generated.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/train_class_0_already_generated.csv')\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={\"real_image\": \"pristine_image\"}, inplace=True)\n",
    "df.rename(columns={\"fake_image\": \"generated_image\"}, inplace=True)\n",
    "df.to_csv(\"csv/train_class_0_already_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also change the value of columns real_image and fake_image in train_class_0_already_generated.csv from real_image=1 and fake_image=0 to real_image=0 and fake_image=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/train_class_0_already_generated.csv')\n",
    "\n",
    "# Swap the values of the two columns\n",
    "df['pristine_image'], df['generated_image'] = df['generated_image'], df['pristine_image']\n",
    "\n",
    "df.to_csv(\"csv/train_class_0_already_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce columns of train_class_0_to_be_generated and train_pristine csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/train_class_0_to_be_generated.csv')\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={\"clean_title\": \"original_caption\"}, inplace=True)\n",
    "\n",
    "df['pristine_image'] = 1\n",
    "df['generated_image'] = 0\n",
    "df['real_text'] = 1\n",
    "df['fakenews_text'] = 0\n",
    "\n",
    "# Select only the desired columns in the required order\n",
    "desired_columns = ['id', 'author', 'original_caption', 'num_comments', '6_way_label', 'pristine_image', 'generated_image', 'real_text', 'fakenews_text']\n",
    "df = df[desired_columns]\n",
    "\n",
    "df.to_csv(\"csv/train_class_0_to_be_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/train_pristine.csv')\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={\"clean_title\": \"original_caption\"}, inplace=True)\n",
    "\n",
    "df['pristine_image'] = 1\n",
    "df['generated_image'] = 0\n",
    "df['real_text'] = 1\n",
    "df['fakenews_text'] = 0\n",
    "\n",
    "# Select only the desired columns in the required order\n",
    "desired_columns = ['id', 'author', 'original_caption', 'num_comments', '6_way_label', 'pristine_image', 'generated_image', 'real_text', 'fakenews_text']\n",
    "df = df[desired_columns]\n",
    "\n",
    "df.to_csv(\"csv/train_pristine.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if every id inside the 250k train_tsv_with_class.csv is contained in the union of the 3 csv train_pristine + train_class_0_already_generated + train_class_0_to_be_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215097\n",
      "215097\n",
      "The union of IDs from the first three CSVs corresponds exactly to the IDs from train_tsv_with_class.csv where '6_way_label' = 0.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the 'id' column from the first three CSV files into sets\n",
    "csv1_ids = set(pd.read_csv(\"csv/train_pristine.csv\")['id'])\n",
    "csv2_ids = set(pd.read_csv(\"csv/train_class_0_to_be_generated.csv\")['id'])\n",
    "csv3_ids = set(pd.read_csv(\"csv/train_class_0_already_generated.csv\")['id'])\n",
    "\n",
    "# Find the union of these three sets\n",
    "union_ids = csv1_ids.union(csv2_ids, csv3_ids)\n",
    "\n",
    "csv4_ids = set(pd.read_csv(\"C:/Users/nello/OneDrive - University of Pisa/TESI/TSV_JSON/1_dataset_cleaning/tsv/train_tsv_with_class.tsv\", sep='\\t').loc[pd.read_csv(\"C:/Users/nello/OneDrive - University of Pisa/TESI/TSV_JSON/1_dataset_cleaning/tsv/train_tsv_with_class.tsv\", sep='\\t')['6_way_label'] == 0, 'id'])\n",
    "\n",
    "print(len(union_ids))\n",
    "print(len(csv4_ids))\n",
    "\n",
    "# Check if the union_ids set is equal to the csv4_ids set\n",
    "if union_ids == csv4_ids:\n",
    "    print(\"The union of IDs from the first three CSVs corresponds exactly to the IDs from train_tsv_with_class.csv where '6_way_label' = 0.\")\n",
    "else:\n",
    "    print(\"The union of IDs from the first three CSVs does not correspond exactly to the IDs from train_tsv_with_class.csv where '6_way_label' = 0.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i print out how many StableDiffusion, Dreamlike and Glide images i have already generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where 'fake_id' starts with 'SD': 22350\n",
      "Number of rows where 'fake_id' starts with 'DL': 22044\n",
      "Number of rows where 'fake_id' starts with 'GL': 11216\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"csv/train_class_0_already_generated.csv\")\n",
    "\n",
    "# Count the rows where the 'fake_id' column starts with 'SD', 'DL', or 'GL'\n",
    "count_SD = len(df[df['fake_id'].str.startswith('SD')])\n",
    "count_DL = len(df[df['fake_id'].str.startswith('DL')])\n",
    "count_GL = len(df[df['fake_id'].str.startswith('GL')])\n",
    "\n",
    "print(\"Number of rows where 'fake_id' starts with 'SD':\", count_SD)\n",
    "print(\"Number of rows where 'fake_id' starts with 'DL':\", count_DL)\n",
    "print(\"Number of rows where 'fake_id' starts with 'GL':\", count_GL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, to get to 107.549 generated images i want to generate other:\n",
    "\n",
    "- SD: 40.000 - 22.350 = 17.650\n",
    "- DL: 40.000 - 22.044 = 17.956\n",
    "- GL: (107.549 - 80.000) - 11.216 = 16.333\n",
    "\n",
    "so 51.939 in total from the train_class_0_to_be_generated.csv, but first i need to caption all the images from train_class_0_to_be_generated.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching images: 51939\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the 'id' column from the CSV file into a set\n",
    "csv_ids = set(pd.read_csv(\"csv/train_class_0_to_be_generated.csv\")['id'])\n",
    "\n",
    "# Get a list of all the image filenames in the folder\n",
    "folder_path = \"C:/Users/nello/Desktop/TESI/dataset_after_merging_WITH_DUPLICATES\"\n",
    "folder_images = set(filename.split('.')[0] for filename in os.listdir(folder_path))\n",
    "\n",
    "# Find the intersection to identify matching images\n",
    "matching_images = csv_ids.intersection(folder_images)\n",
    "\n",
    "# Count the number of matching images\n",
    "num_matching_images = len(matching_images)\n",
    "\n",
    "print(\"Number of matching images:\", num_matching_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
