{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Type 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN CLASS 0: collect the 55k fakes already generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55610\n",
      "Filtered IDs saved to train_class_0_already_generated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_synthetics.csv')\n",
    "\n",
    "# Filter rows where '6_way_label' equals 0 and 'fake_id' starts with 'SD', 'DL', or 'GL'\n",
    "filtered_rows_SD = df[(df['6_way_label'] == 0) & (df['fake_id'].str.startswith('SD'))]\n",
    "filtered_rows_DL = df[(df['6_way_label'] == 0) & (df['fake_id'].str.startswith('DL'))]\n",
    "filtered_rows_GL = df[(df['6_way_label'] == 0) & (df['fake_id'].str.startswith('GL'))]\n",
    "\n",
    "# Concatenate columns for all groups\n",
    "result = pd.concat([filtered_rows_SD, filtered_rows_DL, filtered_rows_GL])\n",
    "print(len(result))\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result.to_csv('csv/train_class_0_already_generated.csv', index=False)\n",
    "\n",
    "print(\"Filtered IDs saved to train_class_0_already_generated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save a csv for the 107k pristine and the 107k-55k to be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train_class_0_already_generated: 55610\n",
      "len of train_pristine: 107548\n",
      "len of train_class_0_to_be_generated: 51939\n",
      "train_class_0_already_generated: 55.610 + train_class_0_to_be_generated: 51.938 = 107548\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MULTIMODAL_TRAIN_CLEANED_WITH_CLASS_TSV = \"C:/Users/nello/OneDrive - University of Pisa/TESI/TSV_JSON/1_dataset_cleaning/tsv/train_tsv_with_class.tsv\"\n",
    "ALREADY_GENERATED_FROM_CLASS_0 = \"csv/train_class_0_already_generated.csv\"\n",
    "\n",
    "train = pd.read_csv(MULTIMODAL_TRAIN_CLEANED_WITH_CLASS_TSV, sep='\\t')\n",
    "train_filtered = train[train['6_way_label'] == 0]\n",
    "\n",
    "train_class_0_already_generated = pd.read_csv(ALREADY_GENERATED_FROM_CLASS_0)\n",
    "print(\"len of train_class_0_already_generated: \"+str(len(train_class_0_already_generated)))\n",
    "\n",
    "# Filter rows from train DataFrame that are not in the 'id' column of the other DataFrame\n",
    "train_not_in_other = train_filtered[~train_filtered['id'].isin(train_class_0_already_generated['id'])]\n",
    "\n",
    "# Select the first 107,549 rows from train_not_in_other\n",
    "train_pristine = train_not_in_other.head(107548)\n",
    "\n",
    "# Save train_pristine to CSV\n",
    "print(\"len of train_class_0_pristine: \"+str(len(train_pristine)))\n",
    "train_pristine.to_csv('csv/train_class_0_pristine.csv', index=False)\n",
    "\n",
    "# Filter rows from train_filtered that are not in train_class_0_already_generated or train_pristine\n",
    "train_remaining = train_filtered[~train_filtered['id'].isin(train_class_0_already_generated['id']) & ~train_filtered['id'].isin(train_pristine['id'])]\n",
    "\n",
    "# Save the remaining rows to a new CSV file\n",
    "print(\"len of train_class_0_to_be_generated: \"+str(len(train_remaining)))\n",
    "train_remaining.to_csv('csv/train_class_0_to_be_generated.csv', index=False)\n",
    "print(\"train_class_0_already_generated: 55.610 + train_class_0_to_be_generated: 51.938 = \" + str(55610+51938))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename the columns real_image and fake_image to pristine_image and generated_image inside train_class_0_already_generated.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/train_class_0_already_generated.csv')\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={\"real_image\": \"pristine_image\"}, inplace=True)\n",
    "df.rename(columns={\"fake_image\": \"generated_image\"}, inplace=True)\n",
    "df.to_csv(\"csv/train_class_0_already_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also change the value of columns real_image and fake_image in train_class_0_already_generated.csv from real_image=1 and fake_image=0 to real_image=0 and fake_image=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/train_class_0_already_generated.csv')\n",
    "\n",
    "# Swap the values of the two columns\n",
    "df['pristine_image'], df['generated_image'] = df['generated_image'], df['pristine_image']\n",
    "\n",
    "df.to_csv(\"csv/train_class_0_already_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce columns of train_class_0_to_be_generated and train_class_0_pristine csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/train_class_0_to_be_generated.csv')\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={\"clean_title\": \"original_caption\"}, inplace=True)\n",
    "\n",
    "df['pristine_image'] = 1\n",
    "df['generated_image'] = 0\n",
    "df['real_text'] = 1\n",
    "df['fakenews_text'] = 0\n",
    "\n",
    "# Select only the desired columns in the required order\n",
    "desired_columns = ['id', 'author', 'original_caption', 'num_comments', '6_way_label', 'pristine_image', 'generated_image', 'real_text', 'fakenews_text']\n",
    "df = df[desired_columns]\n",
    "\n",
    "df.to_csv(\"csv/train_class_0_to_be_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/train_class_0_pristine.csv')\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={\"clean_title\": \"original_caption\"}, inplace=True)\n",
    "\n",
    "df['pristine_image'] = 1\n",
    "df['generated_image'] = 0\n",
    "df['real_text'] = 1\n",
    "df['fakenews_text'] = 0\n",
    "\n",
    "# Select only the desired columns in the required order\n",
    "desired_columns = ['id', 'author', 'original_caption', 'num_comments', '6_way_label', 'pristine_image', 'generated_image', 'real_text', 'fakenews_text']\n",
    "df = df[desired_columns]\n",
    "\n",
    "df.to_csv(\"csv/train_class_0_pristine.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if every id inside the 250k train_tsv_with_class.csv is contained in the union of the 3 csv train_pristine + train_class_0_already_generated + train_class_0_to_be_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215097\n",
      "215097\n",
      "The union of IDs from the first three CSVs corresponds exactly to the IDs from train_tsv_with_class.csv where '6_way_label' = 0.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the 'id' column from the first three CSV files into sets\n",
    "csv1_ids = set(pd.read_csv(\"csv/train_pristine.csv\")['id'])\n",
    "csv2_ids = set(pd.read_csv(\"csv/train_class_0_to_be_generated.csv\")['id'])\n",
    "csv3_ids = set(pd.read_csv(\"csv/train_class_0_already_generated.csv\")['id'])\n",
    "\n",
    "# Find the union of these three sets\n",
    "union_ids = csv1_ids.union(csv2_ids, csv3_ids)\n",
    "\n",
    "csv4_ids = set(pd.read_csv(\"C:/Users/nello/OneDrive - University of Pisa/TESI/TSV_JSON/1_dataset_cleaning/tsv/train_tsv_with_class.tsv\", sep='\\t').loc[pd.read_csv(\"C:/Users/nello/OneDrive - University of Pisa/TESI/TSV_JSON/1_dataset_cleaning/tsv/train_tsv_with_class.tsv\", sep='\\t')['6_way_label'] == 0, 'id'])\n",
    "\n",
    "print(len(union_ids))\n",
    "print(len(csv4_ids))\n",
    "\n",
    "# Check if the union_ids set is equal to the csv4_ids set\n",
    "if union_ids == csv4_ids:\n",
    "    print(\"The union of IDs from the first three CSVs corresponds exactly to the IDs from train_tsv_with_class.csv where '6_way_label' = 0.\")\n",
    "else:\n",
    "    print(\"The union of IDs from the first three CSVs does not correspond exactly to the IDs from train_tsv_with_class.csv where '6_way_label' = 0.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i print out how many StableDiffusion, Dreamlike and Glide images i have already generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where 'fake_id' starts with 'SD': 22350\n",
      "Number of rows where 'fake_id' starts with 'DL': 22044\n",
      "Number of rows where 'fake_id' starts with 'GL': 11216\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"csv/train_class_0_already_generated.csv\")\n",
    "\n",
    "# Count the rows where the 'fake_id' column starts with 'SD', 'DL', or 'GL'\n",
    "count_SD = len(df[df['fake_id'].str.startswith('SD')])\n",
    "count_DL = len(df[df['fake_id'].str.startswith('DL')])\n",
    "count_GL = len(df[df['fake_id'].str.startswith('GL')])\n",
    "\n",
    "print(\"Number of rows where 'fake_id' starts with 'SD':\", count_SD)\n",
    "print(\"Number of rows where 'fake_id' starts with 'DL':\", count_DL)\n",
    "print(\"Number of rows where 'fake_id' starts with 'GL':\", count_GL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, to get to 107.549 generated images i want to generate other:\n",
    "\n",
    "- SD: 40.000 - 22.350 = 17.650\n",
    "- DL: 40.000 - 22.044 = 17.956\n",
    "- GL: (107.549 - 80.000) - 11.216 = 16.333\n",
    "\n",
    "so 51.939 in total from the train_class_0_to_be_generated.csv, but first i need to caption all the images from train_class_0_to_be_generated.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check that every pristine image inside train_class_0_to_be_generated csv is already in the image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching images: 51939\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the 'id' column from the CSV file into a set\n",
    "csv_ids = set(pd.read_csv(\"csv/train_class_0_to_be_generated.csv\")['id'])\n",
    "\n",
    "# Get a list of all the image filenames in the folder\n",
    "folder_path = \"C:/Users/nello/Desktop/TESI/dataset_after_merging_WITH_DUPLICATES\"\n",
    "folder_images = set(filename.split('.')[0] for filename in os.listdir(folder_path))\n",
    "\n",
    "# Find the intersection to identify matching images\n",
    "matching_images = csv_ids.intersection(folder_images)\n",
    "\n",
    "# Count the number of matching images\n",
    "num_matching_images = len(matching_images)\n",
    "\n",
    "print(\"Number of matching images:\", num_matching_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Type 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now construct the train \"type 2\" part, thus the 85k pristine with 6_way_label == 1,2,3,5 (4 manipulated deleted) and 85k generated still with 6_way_label == 1,2,3,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44390\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('C:/Users/nello/Documents/vscode_projects/Thesis/3_image_generation/generated_images/csv/train_synthetics.csv')\n",
    "\n",
    "# Filter rows where '6_way_label' equals 1, 2, 3, or 5 and 'fake_id' starts with 'SD', 'DL', or 'GL'\n",
    "filtered_rows = df[(df['6_way_label'].isin([1, 2, 3, 5])) & (df['fake_id'].str.startswith(('SD', 'DL', 'GL')))]\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "print(len(filtered_rows))\n",
    "filtered_rows.to_csv('csv/train/train_class_1_2_3_5_already_generated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save a csv for the 85k pristine and the 85k-44k to be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train_class_1_2_3_5_already_generated: 44390\n",
      "len of train_class_1_2_3_5_pristine: 85387\n",
      "len of train_class_1_2_3_5_to_be_generated: 40997\n",
      "train_class_1_2_3_5_already_generated: 44.390 + train_class_1_2_3_5_to_be_generated: 40.997 = 85387\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MULTIMODAL_TRAIN_CLEANED_WITH_CLASS_TSV = \"C:/Users/nello/OneDrive - University of Pisa/TESI/TSV_JSON/1_dataset_cleaning/tsv/train_tsv_with_class.tsv\"\n",
    "ALREADY_GENERATED_FROM_CLASS_1_2_3_5 = \"csv/train/train_class_1_2_3_5_already_generated.csv\"\n",
    "\n",
    "train = pd.read_csv(MULTIMODAL_TRAIN_CLEANED_WITH_CLASS_TSV, sep='\\t')\n",
    "train_filtered = train[train['6_way_label'].isin([1, 2, 3, 5])]\n",
    "\n",
    "train_class_0_already_generated = pd.read_csv(ALREADY_GENERATED_FROM_CLASS_1_2_3_5)\n",
    "print(\"len of train_class_1_2_3_5_already_generated: \"+str(len(train_class_0_already_generated)))\n",
    "\n",
    "# Filter rows from train DataFrame that are not in the 'id' column of the other DataFrame\n",
    "train_not_in_other = train_filtered[~train_filtered['id'].isin(train_class_0_already_generated['id'])]\n",
    "\n",
    "# Select the first 107,549 rows from train_not_in_other\n",
    "train_pristine = train_not_in_other.head(85387)\n",
    "\n",
    "# Save train_pristine to CSV\n",
    "print(\"len of train_class_1_2_3_5_pristine: \"+str(len(train_pristine)))\n",
    "train_pristine.to_csv('csv/train/train_class_1_2_3_5_pristine.csv', index=False)\n",
    "\n",
    "# Filter rows from train_filtered that are not in train_class_0_already_generated or train_pristine\n",
    "train_remaining = train_filtered[~train_filtered['id'].isin(train_class_0_already_generated['id']) & ~train_filtered['id'].isin(train_pristine['id'])]\n",
    "\n",
    "# Save the remaining rows to a new CSV file\n",
    "print(\"len of train_class_1_2_3_5_to_be_generated: \"+str(len(train_remaining)))\n",
    "train_remaining.to_csv('csv/train/train_class_1_2_3_5_to_be_generated.csv', index=False)\n",
    "print(\"train_class_1_2_3_5_already_generated: 44.390 + train_class_1_2_3_5_to_be_generated: 40.997 = \" + str(44390+40997))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename the columns real_image and fake_image to pristine_image and generated_image inside train_class_1_2_3_5_already_generated.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/train/train_class_1_2_3_5_already_generated.csv')\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={\"real_image\": \"pristine_image\"}, inplace=True)\n",
    "df.rename(columns={\"fake_image\": \"generated_image\"}, inplace=True)\n",
    "df.to_csv(\"csv/train/train_class_1_2_3_5_already_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also change the value of columns real_image and fake_image in train_class_1_2_3_5_already_generated.csv from real_image=1 and fake_image=0 to real_image=0 and fake_image=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/train/train_class_1_2_3_5_already_generated.csv')\n",
    "\n",
    "# Swap the values of the two columns\n",
    "df['pristine_image'], df['generated_image'] = df['generated_image'], df['pristine_image']\n",
    "\n",
    "df.to_csv(\"csv/train/train_class_1_2_3_5_already_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce columns of train_class_1_2_3_5_to_be_generated and train_class_1_2_3_5_pristine csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/train/train_class_1_2_3_5_to_be_generated.csv')\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={\"clean_title\": \"original_caption\"}, inplace=True)\n",
    "\n",
    "df['pristine_image'] = 1\n",
    "df['generated_image'] = 0\n",
    "df['real_text'] = 0\n",
    "df['fakenews_text'] = 1\n",
    "\n",
    "# Select only the desired columns in the required order\n",
    "desired_columns = ['id', 'author', 'original_caption', 'num_comments', '6_way_label', 'pristine_image', 'generated_image', 'real_text', 'fakenews_text']\n",
    "df = df[desired_columns]\n",
    "\n",
    "df.to_csv(\"csv/train/train_class_1_2_3_5_to_be_generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/train/train_class_1_2_3_5_pristine.csv')\n",
    "\n",
    "# Rename the column\n",
    "df.rename(columns={\"clean_title\": \"original_caption\"}, inplace=True)\n",
    "\n",
    "df['pristine_image'] = 1\n",
    "df['generated_image'] = 0\n",
    "df['real_text'] = 0\n",
    "df['fakenews_text'] = 1\n",
    "\n",
    "# Select only the desired columns in the required order\n",
    "desired_columns = ['id', 'author', 'original_caption', 'num_comments', '6_way_label', 'pristine_image', 'generated_image', 'real_text', 'fakenews_text']\n",
    "df = df[desired_columns]\n",
    "\n",
    "df.to_csv(\"csv/train/train_class_1_2_3_5_pristine.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the distribution of the original classes (1,2,3,5) for the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for each unique value of '6_way_label':\n",
      "6_way_label\n",
      "2    52898\n",
      "1    16290\n",
      "5    10484\n",
      "3     5715\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/train/train_class_1_2_3_5_pristine.csv')\n",
    "\n",
    "# Count the number of rows for each value of '6_way_label'\n",
    "label_counts = df['6_way_label'].value_counts()\n",
    "\n",
    "# Print the counts for each unique value of '6_way_label'\n",
    "print(\"Counts for each unique value of '6_way_label':\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for each unique value of '6_way_label':\n",
      "6_way_label\n",
      "2    27339\n",
      "1     8566\n",
      "5     5565\n",
      "3     2920\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('csv/train/train_class_1_2_3_5_already_generated.csv')\n",
    "\n",
    "# Count the number of rows for each value of '6_way_label'\n",
    "label_counts = df['6_way_label'].value_counts()\n",
    "\n",
    "# Print the counts for each unique value of '6_way_label'\n",
    "print(\"Counts for each unique value of '6_way_label':\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for '6_way_label' 1:\n",
      "Starts with 'SD': 3423\n",
      "Starts with 'GL': 1681\n",
      "Starts with 'DL': 3462\n",
      "\n",
      "Counts for '6_way_label' 2:\n",
      "Starts with 'SD': 10887\n",
      "Starts with 'GL': 5429\n",
      "Starts with 'DL': 11023\n",
      "\n",
      "Counts for '6_way_label' 3:\n",
      "Starts with 'SD': 1125\n",
      "Starts with 'GL': 588\n",
      "Starts with 'DL': 1207\n",
      "\n",
      "Counts for '6_way_label' 5:\n",
      "Starts with 'SD': 2215\n",
      "Starts with 'GL': 1086\n",
      "Starts with 'DL': 2264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/train/train_class_1_2_3_5_already_generated.csv')\n",
    "\n",
    "# Group the DataFrame by '6_way_label'\n",
    "grouped = df.groupby('6_way_label')\n",
    "\n",
    "# Iterate over each group\n",
    "for label, group in grouped:\n",
    "    # Filter the group where 'id' column starts with \"SD\", \"GL\", or \"DL\"\n",
    "    sd_count = len(group[group['fake_id'].str.startswith('SD')])\n",
    "    gl_count = len(group[group['fake_id'].str.startswith('GL')])\n",
    "    dl_count = len(group[group['fake_id'].str.startswith('DL')])\n",
    "    \n",
    "    # Print counts for each value of '6_way_label'\n",
    "    print(f\"Counts for '6_way_label' {label}:\")\n",
    "    print(f\"Starts with 'SD': {sd_count}\")\n",
    "    print(f\"Starts with 'GL': {gl_count}\")\n",
    "    print(f\"Starts with 'DL': {dl_count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated with SD:\n",
      "6_way_label: 1 in the interval [0, 12350): 2356\n",
      "6_way_label: 2 in the interval [0, 12350): 7614\n",
      "6_way_label: 3 in the interval [0, 12350): 860\n",
      "6_way_label: 5 in the interval [0, 12350): 1520\n",
      "\n",
      "Generated with DL:\n",
      "6_way_label: 1 in the interval [12350, 24394): 2315\n",
      "6_way_label: 2 in the interval [12350, 24394): 7437\n",
      "6_way_label: 3 in the interval [12350, 24394): 806\n",
      "6_way_label: 5 in the interval [12350, 24394): 1486\n",
      "\n",
      "Generated with GL:\n",
      "6_way_label: 1 in the interval [24394, 40997): 3146\n",
      "6_way_label: 2 in the interval [24394, 40997): 10315\n",
      "6_way_label: 3 in the interval [24394, 40997): 1080\n",
      "6_way_label: 5 in the interval [24394, 40997): 2062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('csv/train/train_class_1_2_3_5_to_be_generated.csv')\n",
    "\n",
    "# Define the start and end indices for each interval\n",
    "intervals = {\n",
    "    \"Generated with SD\": (0, 12350),\n",
    "    \"Generated with DL\": (12350, 24394),\n",
    "    \"Generated with GL\": (24394, len(df))\n",
    "}\n",
    "\n",
    "# Iterate over each interval\n",
    "for method, (start_index, end_index) in intervals.items():\n",
    "    # Filter the DataFrame based on the interval\n",
    "    interval_df = df.iloc[start_index:end_index]\n",
    "    \n",
    "    # Group the interval DataFrame by '6_way_label'\n",
    "    grouped = interval_df.groupby('6_way_label')\n",
    "    \n",
    "    # Print the count of rows with each '6_way_label' value within the interval\n",
    "    print(f\"{method}:\")\n",
    "    for label, group in grouped:\n",
    "        label_count = len(group)\n",
    "        print(f\"6_way_label: {label} in the interval [{start_index}, {end_index}): {label_count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if every id inside the train_tsv_with_class.csv with '6_way_label' = 1,2,3,5 is contained in the union of the 3 csv train_class_1_2_3_5_pristine + train_class_1_2_3_5_already_generated + train_class_1_2_3_5_to_be_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170774\n",
      "170774\n",
      "The union of IDs from the first three CSVs corresponds exactly to the IDs from train_tsv_with_class.csv where '6_way_label' = 1,2,3,5.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the 'id' column from the first three CSV files into sets\n",
    "csv1_ids = set(pd.read_csv(\"csv/train/train_class_1_2_3_5_pristine.csv\")['id'])\n",
    "csv2_ids = set(pd.read_csv(\"csv/train/train_class_1_2_3_5_to_be_generated.csv\")['id'])\n",
    "csv3_ids = set(pd.read_csv(\"csv/train/train_class_1_2_3_5_already_generated.csv\")['id'])\n",
    "\n",
    "# Find the union of these three sets\n",
    "union_ids = csv1_ids.union(csv2_ids, csv3_ids)\n",
    "\n",
    "csv4_ids = set(pd.read_csv(\"C:/Users/nello/OneDrive - University of Pisa/TESI/TSV_JSON/1_dataset_cleaning/tsv/train_tsv_with_class.tsv\", sep='\\t').loc[pd.read_csv(\"C:/Users/nello/OneDrive - University of Pisa/TESI/TSV_JSON/1_dataset_cleaning/tsv/train_tsv_with_class.tsv\", sep='\\t')['6_way_label'].isin([1, 2, 3, 5]), 'id'])\n",
    "\n",
    "print(len(union_ids))\n",
    "print(len(csv4_ids))\n",
    "\n",
    "# Check if the union_ids set is equal to the csv4_ids set\n",
    "if union_ids == csv4_ids:\n",
    "    print(\"The union of IDs from the first three CSVs corresponds exactly to the IDs from train_tsv_with_class.csv where '6_way_label' = 1,2,3,5.\")\n",
    "else:\n",
    "    print(\"The union of IDs from the first three CSVs does not correspond exactly to the IDs from train_tsv_with_class.csv where '6_way_label' = 1,2,3,5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, to get to 85.387 generated images i want to generate other 40.997:\n",
    "\n",
    "- SD: 30.000 - 17.650 = 12.350\n",
    "- DL: 30.000 - 17.956 = 12.044\n",
    "- GL: (85.387 - 60.000) - 8.784 = 16.603\n",
    "\n",
    "so 40.997 in total from the train_class_1_2_3_5_to_be_generated.csv, but first i need to caption all the images from train_class_1_2_3_5_to_be_generated.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check that every pristine image inside train_class_1_2_3_5_to_be_generated csv is already in the image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching images: 40997\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the 'id' column from the CSV file into a set\n",
    "csv_ids = set(pd.read_csv(\"csv/train/train_class_1_2_3_5_to_be_generated.csv\")['id'])\n",
    "\n",
    "# Get a list of all the image filenames in the folder\n",
    "folder_path = \"C:/Users/nello/Desktop/TESI/dataset_after_merging_WITH_DUPLICATES\"\n",
    "folder_images = set(filename.split('.')[0] for filename in os.listdir(folder_path))\n",
    "\n",
    "# Find the intersection to identify matching images\n",
    "matching_images = csv_ids.intersection(folder_images)\n",
    "\n",
    "# Count the number of matching images\n",
    "num_matching_images = len(matching_images)\n",
    "\n",
    "print(\"Number of matching images:\", num_matching_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the dataset folder from Manipulated Images (class 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images removed: 190185\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_files = ['/home/enriconello/DeepFakeDetection/Thesis/3_image_generation/generated_images/csv/train.csv',\n",
    "             '/home/enriconello/DeepFakeDetection/Thesis/3_image_generation/generated_images/csv/test_with_duplicates.csv',\n",
    "             '/home/enriconello/DeepFakeDetection/Thesis/3_image_generation/generated_images/csv/validation_with_duplicates.csv']\n",
    "\n",
    "# image folder path \n",
    "image_folder = '/home/enriconello/DeepFakeDetection/dataset'\n",
    "\n",
    "unique_ids = set()\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Filter rows where '6_way_label' equals to the class Manipulated images\n",
    "    filtered_df = df[df['6_way_label'] == 4]\n",
    "    unique_ids.update(filtered_df['id'])\n",
    "\n",
    "num_images_removed = 0\n",
    "\n",
    "for id_value in unique_ids:\n",
    "    image_path = os.path.join(image_folder, f\"{id_value}.jpg\")\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        os.remove(image_path)\n",
    "        num_images_removed += 1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(f\"Total number of images removed: {num_images_removed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the train_class_1_2_3_5_captioned csv, deleting the generated captions that starts with \"araf\" (buggy captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of updated rows: 7970\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "original_df = pd.read_csv('/home/enriconello/DeepFakeDetection/Thesis/5_biased_detection/csv/train/train_class_1_2_3_5_captioned.csv')\n",
    "\n",
    "# copy of the original DataFrame\n",
    "modified_df = original_df.copy()\n",
    "\n",
    "# replace words starting with \"araf\" in the \"generated_caption\" column with an empty string\n",
    "modified_df['generated_caption'] = modified_df['generated_caption'].str.replace(r'\\baraf\\w*\\b', '', regex=True)\n",
    "modified_df.to_csv(\"/home/enriconello/DeepFakeDetection/Thesis/5_biased_detection/csv/train/train_class_1_2_3_5_captioned.csv\")\n",
    "\n",
    "# count the number of updated rows \n",
    "updated_rows_count = (original_df['generated_caption'] != modified_df['generated_caption']).sum()\n",
    "\n",
    "print(f\"Number of updated rows: {updated_rows_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
